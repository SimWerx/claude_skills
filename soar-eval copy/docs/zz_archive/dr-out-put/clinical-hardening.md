# Medical SME Review: Clinical Hardening & Enhancement

## Executive Summary

The current evaluation benchmarks are well-aligned with EMS documentation standards, but several gaps and refinements are needed for full clinical robustness. Overall, the 46 benchmarks cover most high-risk documentation elements (e.g. refusals, RSI, STEMI, pediatric dosing) and the rubric structure is sound. Key gaps identified include missing tests for medication extraction accuracy, incomplete use of Denver protocol criteria (e.g. restraint monitoring intervals, medication documentation), and a few placeholder benchmarks that require definition. We recommend tightening thresholds for critical items (e.g. negation, safety flags)[\[1\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L2-L10)[\[2\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-SFT.yaml#L15-L23), adding new benchmarks for medication omissions and evidence handling, and strengthening example realism where noted. Addressing these will ensure the evaluation harness fully covers medicolegal and patient safety documentation requirements before deployment.

## Rubric-by-Rubric Clinical Review

### A-NEG (Negation Handling)

**Assessment**: Needs Refinement - core patterns covered, but threshold should be higher given risk[\[1\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L2-L10)[\[3\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L16-L25).  
**Strengths**:  
\- Clearly separates simple vs. complex negation (double negatives, implicit uncertainty)[\[4\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L32-L36).  
\- Includes internal contradiction detection (e.g. "AOx4 but confused")[\[5\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-NEG4.yaml#L28-L36).  
\- Examples are realistic EMS statements ("denies chest pain or SOB") and highlight errors like false positives[\[6\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-NEG1.yaml#L38-L46).

**Issues Found**:  
\- **Threshold too low**: Passing threshold is 0.85; given medicolegal risk of negation errors, this should be stricter[\[1\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L2-L10)[\[3\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L16-L25). SME notes already flag raising to 0.90[\[1\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L2-L10). Mis-documented negatives (e.g. charting a denied allergy as present) can seriously mislead downstream providers.  
\- **Missing nuance**: No explicit test for **partial** negation (e.g. "denies chest pain **except** slight twinge" - nuance between denial and mild symptom). Current benchmarks cover implicit/hedged negation[\[7\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-NEG3.yaml#L8-L16) but not cases where medics qualify a denial.  
\- **Contradiction timing**: A-NEG4 covers simultaneous contradictions[\[5\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-NEG4.yaml#L28-L36), but does not address if Medic Copilot flags them appropriately (presence of a "contradiction noted" flag in output). It just checks detection.

**Recommended Changes**:  
\- \[x\] **Raise rubric threshold to 0.90** for A-NEG category[\[1\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L2-L10)[\[3\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L16-L25). Simple negation should be near-perfect due to high risk of mischarting[\[8\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L22-L28).  
\- \[x\] **Emphasize no false-positive findings**: Add a bullet in critical_requirements: "No negated finding is charted as present" (implied but worth explicit emphasis).  
\- \[ \] **Add example of partial denial**: e.g. _"Denies any chest pain, just mild soreness"_ to ensure the system doesn't flip that to a full positive or negative incorrectly.  
\- \[ \] **Ensure contradiction flagging**: Modify A-NEG4 inclusion to require Medic Copilot either resolve or explicitly flag contradictions[\[5\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-NEG4.yaml#L28-L36). If not flagged, that's a fail.

### A-FCT (Fact Extraction)

**Assessment**: Critical Gap - missing entire sub-areas (medications, procedures) despite clear rubric intent[\[9\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-FCT.yaml#L6-L14)[\[10\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-FCT.yaml#L16-L24).  
**Strengths**:  
\- Vitals extraction is well-defined and strict (0.90 threshold)[\[11\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT1.yaml#L10-L18)[\[12\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT1.yaml#L29-L37), covering all core vitals and scales (pain, glucose) with realistic examples (misheard BP, omitted EtCO2)[\[13\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT1.yaml#L38-L46).  
\- Impression/diagnosis match test (A-FCT4) ensures final documented impression aligns with scenario clinical truth[\[14\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT4.yaml#L9-L17)[\[15\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT4.yaml#L28-L37), including use of synonyms (STEMI vs "acute MI")[\[16\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT4.yaml#L22-L30)[\[17\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT4.yaml#L34-L42). This is crucial for QA and billing.  
\- Rubric guidelines emphasize medication and procedure capture[\[10\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-FCT.yaml#L16-L24), showing SME awareness of their importance.

**Issues Found**:  
\- **Medications & procedures not explicitly tested**: Despite rubric listing meds/procedures, no benchmarks exist for medication extraction accuracy or procedure documentation (e.g. IV placement, 12-lead performed)[\[10\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-FCT.yaml#L16-L24)[\[18\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-FCT.yaml#L26-L28). This is a notable gap: if Medic Copilot fails to record a medication given (say, fentanyl administration) or a procedure done, no current benchmark flags it unless it triggers another rubric (like protocol or safety).  
\- **Benchmarks A-FCT2 & A-FCT3 missing**: The numbering jumps from 1 to 4[\[19\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-FCT.yaml#L32-L35), suggesting placeholders for additional fact types. Critical facts like medication name/dose extraction, procedure notes (e.g. tourniquet applied - though this appears under trauma) are not covered outside of special cases.  
\- **Impression match nuance**: A-FCT4 is solid, but it relies on LLM judgment of equivalence[\[20\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT4.yaml#L39-L48). To ensure clarity, ground-truth impressions should be tightly defined. E.g. "Non-cardiac chest pain" vs "anxiety" example[\[21\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT4.yaml#L38-L46) is clear; however, edge cases like "STEMI vs NSTEMI" or "sepsis vs UTI" might confuse without context.

**Recommended Changes**:  
\- \[x\] **Implement A-FCT2: Medication Extraction** - Add a benchmark ensuring all medications stated in narrative (and not just protocol-mandated ones) appear with correct name and dose in output. E.g. narrative "Morphine 4 mg IV given" but output missing it would fail. This aligns with rubric intent "medications captured with dose, route"[\[10\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-FCT.yaml#L16-L24).  
\- \[x\] **Implement A-FCT3: Procedure Extraction** - Similar for common procedures (IV starts, 12-leads, oxygen therapy) when explicitly dictated. Ensures completeness of interventions beyond drugs.  
\- \[ \] **Tighten vitals inclusion**: Expand A-FCT1 to explicitly mention temperature and EtCO2 as equal priority vitals (currently it does, but ensure test cases include these)[\[11\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT1.yaml#L10-L18). Consider adding a pediatric vital example (e.g. heart rate 180 documented vs output 130).  
\- \[ \] **Monitor LLM eval for impression**: For A-FCT4, perhaps weight can be lower or add a code-check component (e.g. exact string match of ICD codes if available) to supplement LLM judgment. Minor suggestion as current approach is acceptable.

### A-TMP (Temporal Ordering)

**Assessment**: Partially Defined - two benchmarks solid, two undefined placeholders[\[22\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-TMP.yaml#L32-L38)[\[23\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP3.yaml#L9-L17). Clinical scenarios covered are appropriate but need completion.  
**Strengths**:  
\- A-TMP1 (event sequence) addresses critical ordering errors like interventions before prerequisites and transport before on-scene care[\[24\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP1.yaml#L29-L38)[\[25\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP1.yaml#L40-L45). Examples (RSI med order reversed, transport documented too early) are spot-on and clinically relevant.  
\- A-TMP2 (pre/post trends) ensures response to treatment is properly reflected (pain improved vs worsened)[\[26\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP2.yaml#L28-L37)[\[27\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP2.yaml#L38-L45). This is very important for showing interventions worked (or not) in documentation.  
\- Guidelines emphasize preserving chronological integrity, e.g. "Transport must not precede on-scene assessment"[\[28\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-TMP.yaml#L24-L31) and trend direction must be correct[\[29\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-TMP.yaml#L16-L24) - crucial for continuity of care.

**Issues Found**:  
\- **A-TMP3 and A-TMP4 are placeholders**: These benchmarks are not defined at all[\[30\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP3.yaml#L2-L10)[\[31\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP4.yaml#L9-L17). The rubric lists "Protocol step ordering" and "Trend direction accuracy" as intended tests[\[22\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-TMP.yaml#L32-L38), but neither is implemented. This leaves gaps: for example, confirming that a **major protocol sequence** (like cardiac arrest algorithm steps or stroke timeline) is in correct order is not currently validated.  
\- **Protocol step ordering vs event ordering**: A-TMP1 touches on protocol order implicitly (e.g. nitro after 12-lead)[\[32\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP1.yaml#L29-L37), but we might explicitly want to test sequences like **cardiac arrest** (CPR, shocks, epi - in correct loops) or **stroke** (last known well, then stroke alert). Without A-TMP3, these specific sequence checks rely on general logic or other rubric checks.  
\- **Temporal phrasing nuances**: No specific test for preserving explicit times or time gap statements (e.g. "10 minutes later"). The rubric focus mentions timestamps[\[29\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-TMP.yaml#L16-L24), but no benchmark explicitly checks if a stated time ("08:30") is correctly captured. Perhaps considered low-level (format), but clinically "accurate timeline" can matter for stroke (LKW time) or meds timing.

**Recommended Changes**:  
\- \[x\] **Define A-TMP3 (Protocol Step Ordering)** - Implement this benchmark to verify that within a known protocol sequence events are in order. For example: In an RSI scenario, ensure **pre-oxygenation -> sedation -> paralytic -> intubation -> confirmation** are in proper sequence (the narrative ground truth can be used as reference). Similarly for **STEMI**: 12-lead before alert, aspirin before nitro, etc. Ground truth can label the expected order[\[24\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP1.yaml#L29-L38).  
\- \[x\] **Define A-TMP4 (Explicit Timing Consistency)** - Possibly focus on whether documented times and intervals make sense (if provided). E.g. if narrative says "departed scene at 14:30, arrived hospital 14:50" but output swaps them or miscalculates interval. If no narrative times given, this could verify chronological markers like "after 5 minutes" are preserved.  
\- \[ \] **Inclusion of known time-critical protocols** in examples: Add a test case for stroke timeline (onset vs arrival vs alert called) - though stroke specifics are in A-STR, temporal ordering should reinforce that nothing happens "before" time zero.  
\- \[ \] **Thresholds**: Current thresholds (0.85) are reasonable for temporal checks since minor ordering swaps might be less critical. Once A-TMP3/4 are defined, keep them around 0.85 as well unless they cover critical safety steps, then maybe 0.90.

### A-EVD (Evidence Attribution)

**Assessment**: Needs Refinement - concept is excellent and crucial for auditability, but only partially implemented (second benchmark undefined)[\[33\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-EVD.yaml#L24-L32)[\[34\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-EVD3.yaml#L9-L17).  
**Strengths**:  
\- Emphasizes that every structured fact should have supporting narrative evidence[\[35\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-EVD.yaml#L16-L24). A-EVD1 ("Evidence span presence") directly checks for missing or incorrect evidence mapping[\[36\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-EVD1.yaml#L28-L36)[\[37\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-EVD1.yaml#L38-L45) - a critical requirement for trust. Example of impression mapped to irrelevant span is on point[\[37\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-EVD1.yaml#L38-L45).  
\- Critical requirements clearly state **safety-critical facts must have evidence** and evidence must actually support the claim[\[33\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-EVD.yaml#L24-L32). This aligns with protocol expectations that documentation be traceable, especially for high-risk entries (doses, procedures).  
\- Acceptable deviations allow paraphrasing and multiple valid spans[\[38\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-EVD.yaml#L20-L28), which is realistic (medics might describe one fact in different ways).

**Issues Found**:  
\- **A-EVD3 is placeholder**: Intended to cover an additional evidence check (likely span accuracy or contradiction) but not defined[\[39\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-EVD3.yaml#L2-L10). One major gap here is **contradictory evidence** - e.g., if narrative says one thing and Medic Copilot documents the opposite without flagging. The rubric notes "contradictory evidence must be flagged" as a requirement[\[33\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-EVD.yaml#L24-L32), but no benchmark explicitly tests that. This could be the purpose of A-EVD3.  
\- **Scope of evidence mapping**: A-EVD1 focuses on missing spans or unsupported spans[\[36\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-EVD1.yaml#L28-L36). We might also want to test if **extraneous evidence** is attached (e.g., mapping an entire paragraph when only one line is relevant). Currently acceptable deviations allow "extra context words"[\[38\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-EVD.yaml#L20-L28), so that's fine, but if the span is wildly beyond the fact, is that caught? Possibly in manual review, but no explicit fail unless it's clearly wrong content.  
\- **Examples limited**: Only two brief examples for A-EVD1[\[37\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-EVD1.yaml#L38-L45). Could include a positive example of correct evidence mapping for clarity (though not strictly required). Also, no example of contradictory evidence scenario, which is arguably high priority (e.g., narrative: "No wheezing"; output: wheezing true, and evidence span was "no wheezing" - a blatant mis-map).

**Recommended Changes**:  
\- \[x\] **Define A-EVD3** - likely focus on **Evidence Contradiction or Irrelevance**. For instance, if ground truth flags that Medic Copilot should have noticed a piece of text that contradicts an output field, ensure the output flagged it. Alternatively, A-EVD3 can verify that evidence spans chosen do not _conflict_ with the extracted fact. E.g. mapping "denies chest pain" as evidence for chest_pain: true should fail (this overlaps with negation, but from evidence perspective)[\[36\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-EVD1.yaml#L28-L36)[\[37\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-EVD1.yaml#L38-L45).  
\- \[ \] **Add contradictory evidence example**: e.g. _"Output says allergy: penicillin with evidence span 'No known drug allergies'"_ - clearly a fail (could fall under both negation and evidence rules). Show how that would be caught (likely by the new A-EVD3).  
\- \[ \] **Slight threshold increase**: Passing threshold is 0.80 for rubric[\[40\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-EVD.yaml#L10-L18) and 0.90 for A-EVD1[\[41\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-EVD1.yaml#L12-L20). Given evidence mapping is fundamental but some minor lapses might occur, 0.90 overall is acceptable. We might suggest raising rubric threshold to 0.85 (if additional benchmarks added) so that nearly all facts have evidence. Safety-critical ones must be 100% anyway by rubric requirement[\[33\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-EVD.yaml#L24-L32) (and presumably scenario weighting).  
\- \[ \] **Ensure alignment with scope**: Clarify in acceptable deviations that if a field is inferred by context (but narrative lacks an explicit span - e.g., medic infers patient age from context), not having a direct span is acceptable if marked appropriately. The rubric hints at this ("legitimately inferred from context")[\[38\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-EVD.yaml#L20-L28) but test cases should reflect it (perhaps via not applying A-EVD benchmarks in such cases).

### A-CMP (Completeness)

**Assessment**: Needs Refinement - covers many crucial completeness checks, but some sections remain untested (placeholders for specific sections) and example scenarios could broaden.  
**Strengths**:  
\- A-CMP1 ensures **core DRAATT sections exist** whenever they should[\[42\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP1.yaml#L28-L37). This is fundamental - missing an entire section like "Transport" or "Assessment" is a major documentation error. The benchmark smartly accounts for template-specific omissions (e.g. RSI overlay might legitimately omit some sections)[\[43\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP1.yaml#L32-L40).  
\- Specialized completeness checks are included: **A-CMP5** for field pronouncement (DOA) documentation[\[44\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L9-L17)[\[45\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L28-L36) and **A-CMP6** for transport/handoff details[\[46\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP6.yaml#L10-L18)[\[47\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP6.yaml#L29-L37). These mirror protocol mandates: Protocol 0050 requires pronouncement time/physician etc.[\[44\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L9-L17)[\[45\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L28-L36), and good practice requires documenting mode of transport, receiving facility, incidents en route[\[47\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP6.yaml#L29-L37).  
\- Inclusion of **A-CMP6-airport** addresses a niche but important scenario (ground-to-air transfers)[\[48\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP6-airport.yaml#L9-L17)[\[49\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP6-airport.yaml#L29-L37), which shows forward-thinking about less common use cases.  
\- **A-ALL1 (Allergy)** being grouped under completeness is appropriate - omissions of stated allergies are completeness failures[\[50\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-ALL1.yaml#L9-L17)[\[51\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-ALL1.yaml#L29-L37). This benchmark is well-defined with examples (including proper handling of "NKDA")[\[52\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-ALL1.yaml#L30-L38)[\[53\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-ALL1.yaml#L41-L48).

**Issues Found**:  
\- **Placeholders A-CMP2, A-CMP3, A-CMP4**: These appear reserved for specific section completeness (likely Response, Arrival, Assessment respectively) but remain undefined[\[54\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-CMP.yaml#L33-L41). As a result, there is no fine-grained check that within a present section, key fields are populated. For example, if an **Assessment section exists but vital exam elements are missing**, no specific benchmark flags that (unless it triggers something like A-TRM or A-STR). Similarly, **Arrival scene details** (e.g. patient position found, environment hazards) completeness isn't explicitly tested due to A-CMP3 placeholder.  
\- **Assessment completeness vs extraction**: The boundary between extraction failures and completeness can blur. E.g., missing a lung exam finding could be seen as an extraction miss or an assessment incompleteness. Currently, if it's stated in narrative and missing, A-FCT or A-NEG would catch it; if it's not stated at all and missing, that's not a failure by design (scope boundary). However, protocols often list required exam elements. For instance, trauma protocol (8000) expects a GCS and exam; if Medic Copilot outputs an Assessment section with only "see above" or very minimal info, should that fail completeness? Possibly yes.  
\- **No direct check for Refusal form completeness** under A-CMP: However, A-REF rubric covers those elements. So that's acceptable separation. Just ensure no redundancy needed here.  
\- **Examples and weights**: A-CMP1's examples of missing sections are good (no Response or Transport documented)[\[55\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP1.yaml#L38-L46). We might add an example where sections were conflated (to utilize that inclusion note about conflation) - e.g. narrative clearly had separate dispatch info but output mixed it into arrival notes. Weighting: A-CMP1 is weighted 0.167 each for sections[\[56\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP1.yaml#L13-L21), which is fine. A-CMP5 and A-CMP6 are 0.167 each as well[\[57\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L13-L20)[\[58\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP6.yaml#L14-L21), indicating all these completeness pieces sum up the rubric. That seems balanced.  
\- **A-CMP6-airport overlap**: It's listed separately but presumably part of rubric. It has same weight 0.167[\[59\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP6-airport.yaml#L14-L22). Should A-CMP6-airport perhaps be a subset or example of A-CMP6? It's fine as separate since criteria differ, but just a note that both cover similar ground (transport completeness).

**Recommended Changes**:  
\- \[x\] **Define A-CMP2, A-CMP3, A-CMP4** - Even if briefly, to address completeness of **Response**, **Arrival**, **Assessment** sections. For example:  
\- _A-CMP2 (Response Complete)_: Does the unit response section capture crew ID, timestamps, and scene arrival delays if any? E.g., if narrative mentioned a delayed response or upgrade, ensure output logs it.  
\- _A-CMP3 (Arrival/Scene Complete)_: Are scene details (mechanism in trauma, bystander info, safety hazards) documented if given? E.g., mechanism of injury in trauma narrative must appear (though A-TRM1 also covers mechanism) - this can integrate with protocol 8000 "General Trauma Care" requiring mechanism documentation[\[60\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM1.yaml#L9-L17).  
\- _A-CMP4 (Assessment Complete)_: Verify that a head-to-toe assessment (or pertinent exam) is present if narrative had details. For instance, if narrative lists lung, heart, neuro exams, output shouldn't omit an entire system. This might be partially covered by A-NEG (if negations omitted) and specialty rubrics (stroke, trauma), but a generic check ensures no major exam finding is dropped.  
\- \[ \] **Coordinate with extraction**: Make clear in FIELD_SPECS that if a section is present but missing specific elements that were _stated_ in narrative, it's an extraction issue (A-FCT, A-NEG, etc.), whereas A-CMP covers when narrative had content and output left the section blank or missing a whole subsection. This avoids double-penalizing or leaving gaps. (The scope boundary in the README indicates eval is ground-truth driven[\[61\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/README.md#L59-L67), so we likely only test where narrative had something - just restating this logic in completeness context.)  
\- \[ \] **Enhance examples**: For A-CMP6 (Transport), add an example specific to handoff documentation: _"Output fails to mention patient condition upon ED arrival"_[\[47\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP6.yaml#L29-L37) - a common omission medics sometimes make that's important (protocol often requires noting if patient condition improved, worsened, or unchanged at transfer). Currently example covers not mentioning who received patient[\[62\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP6.yaml#L40-L46), we can add condition on arrival as another key field (already in inclusion criteria) to emphasize it.  
\- \[ \] **Allergy threshold**: A-ALL1 threshold 0.90 is fine[\[63\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-ALL1.yaml#L14-L22) given maybe spelling variants, but we might even argue for 1.0 since an allergy omission is high risk. However, since it's under completeness with weight only 0.10, leaving at 0.90 is acceptable - it means one missed allergy in a list of 10 might still allow passing, which might be lenient. Consider 1.0 hard gate if even a single allergy is omitted (we lean toward stricter).

### A-SFT (Safety Flags)

**Assessment**: Sound - this rubric appropriately treats safety issues with zero tolerance[\[64\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-SFT.yaml#L10-L19)[\[65\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-SFT.yaml#L24-L32). A couple threshold inconsistencies noted, but overall captures critical failures.  
**Strengths**:  
\- **MINIMUM aggregation, threshold 1.0** for rubric[\[66\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-SFT.yaml#L11-L19) means any safety lapse fails the category - this is absolutely appropriate (one unchecked unsafe dose is enough for concern).  
\- Benchmarks target top medicolegal threats:  
\- **A-SFT1** checks medication dosing/routes that are clearly unsafe (e.g. 10x overdose or wrong route)[\[67\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT1.yaml#L9-L17)[\[68\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT1.yaml#L36-L42). Example of 3240 mg aspirin (instead of 324 mg)[\[69\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT1.yaml#L34-L42) directly reflects a real error that must never go unflagged.  
\- **A-SFT2** covers contraindications ignored[\[70\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT2.yaml#L10-L18) - exactly what protocols demand we avoid. Examples map to Denver protocols: allergic to a med but given anyway, PDE5 inhibitor with nitro given[\[71\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT2.yaml#L28-L36)【46†L37-L40}. Even SBP <90 and nitro given is in example[\[84\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT2.yaml#L38-L41) (Denver Chest Pain protocol forbids nitro if hypotensive, so this is on target).  
\- **A-SFT4** ensures post-intervention reassessments (like vitals after giving morphine or intubation) are done[\[72\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT4.yaml#L9-L17)[\[73\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT4.yaml#L38-L46). This aligns with protocol mandates (e.g. sedation requires Q5-15 monitoring, restrained patients check circulations q15) - see Denver restraint protocol requiring continuous monitoring and periodic checks[\[74\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=F,escalate%20prior%20to%20restraint)[\[75\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=3,care%20to%20emergency%20department%20staff). The examples (no post-nitro BP, no post-RSI EtCO2, etc.) hit these points[\[73\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT4.yaml#L38-L46).  
\- **Criticality settings**: A-SFT1, A-SFT2 are hard_gate with threshold 1.0[\[76\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT1.yaml#L12-L20)[\[77\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT2.yaml#L13-L21) - meaning any such error is a failure, which is correct (we _must_ flag an unflagged unsafe dose or allergy conflict). A-SFT4 has threshold 0.90[\[78\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT4.yaml#L14-L22), which still effectively fails rubric if it drops below since rubric needs 1.0 min.

**Issues Found**:  
\- **A-SFT3 is missing**: It appears there was no A-SFT3. The rubric lists 1, 2, 4[\[79\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-SFT.yaml#L35-L38). Possibly A-SFT3 was intended for another safety scenario (perhaps something like _equipment misuse_ or _CPR protocol deviation_), but not sure. This is a minor numbering oddity; if no content was intended, no issue - but if something like **"failure to flag unsafe combination or absence of safety equipment"** was dropped, we should confirm no gap. (One potential gap: **Pediatric safety** - but that is covered in A-PED1 for dosing). Another could be **failure to ensure scene safety or provider safety** - but that's outside AI scope. So likely fine.  
\- **Inconsistent threshold on A-SFT4**: As noted, rubric is MIN 1.0, so A-SFT4 having 0.90 threshold is mostly academic - the rubric will fail unless it's 1.0. For consistency and clarity, we might make A-SFT4 threshold 1.0 as well (since missing a required reassessment is arguably as critical - e.g. not checking vitals after sedating could be deadly). However, one could argue minor lapses (missing one out of a few vitals) might still get 0.9 and be acceptable. Given rubric logic, any <1.0 fails anyway[\[80\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-SFT.yaml#L12-L19)[\[81\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-SFT.yaml#L26-L30), so either set A-SFT4 to 1.0 or leave as is with understanding that rubric threshold governs.  
\- **Scope of A-SFT4**: It lists many high-risk interventions (nitro, opioids, paralytics, intubation, cardioversion, restraints)[\[72\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT4.yaml#L9-L17). Good. We should ensure scenarios cover each. One notable inclusion is physical restraints - indeed Denver protocol requires q15 checks and documentation of neurovascular status[\[74\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=F,escalate%20prior%20to%20restraint), so a scenario where narrative says "restrained at 22:00, circulation rechecked q15" and output fails to record any follow-up could be used. A-SFT4 examples do mention restraints ("no reassessment of circulation or status after restraints applied")[\[82\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT4.yaml#L39-L43) - excellent.  
\- **Base contact for overrides**: The rubric's acceptable deviation says "contraindication override documented with rationale"[\[83\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-SFT.yaml#L20-L28). We should ensure scenarios exist where Medic Copilot is expected to not flag something because medic had a valid reason (e.g. Epi given despite allergy because benefit > risk and they documented base physician told them to). This nuance might be tricky to auto-evaluate, but is mentioned. No specific benchmark, just keep in mind for labeling.

**Recommended Changes**:  
\- \[ \] **Consider A-SFT3 (if any)**: Confirm that no other "safety flag" type was intended. One possibility: _Failure to recognize deteriorating vital trends_ (but that's more clinical judgment than extraction). Probably safe to leave numbering gap, but document it.  
\- \[x\] **Set A-SFT4 threshold to 1.0** (or rubric threshold slightly below 1.0) _or_ explicitly note in rubric that any A-SFT4 <1.0 causes rubric fail due to MIN aggregator. For clarity to future devs/SMEs reading YAML, aligning them all as hard_gate might avoid confusion. As an SME, I advocate treating missing a post-intervention check as critical - the difference between catching an adverse reaction or not.  
\- \[ \] **Expand examples to full narrative context** for A-SFT1 and A-SFT2: E.g., A-SFT2 could include "BP 88/60 in vitals, yet nitro given with no note"[\[84\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT2.yaml#L38-L41) - which it does. Maybe add one more like "Known sulfa allergy, medic gave Lasix - output doesn't mention any alert" (just to reinforce variety of contra scenarios beyond what's listed). Current examples are solid though.  
\- \[ \] **Add scenario with documented override**: To test acceptable deviation, include a ground truth where medic gave a contraindicated med _with_ base contact and rationale in narrative. The expected output would have a note like "(given per Dr. X order despite allergy)". Then ensure the evaluation doesn't penalize (or even rewards) that. This could be a manual SME review item rather than automated, but worth noting.

### A-PRT (Protocol Tracking)

**Assessment**: Sound - focuses on two high-impact protocol scenarios (RSI and STEMI) and aligns with Denver protocols. Minor additions could broaden scope to other protocols, but current ones are well-chosen.  
**Strengths**:  
\- **RSI documentation (A-PRT1)** is comprehensive: it checks all mandatory elements - indication, pre-oxygenation, sedative & paralytic (and doses), ETT size/depth, EtCO₂ confirmation, number of attempts[\[85\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L10-L18)[\[86\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L30-L38). This directly reflects protocol 1000 Intubation requirements (e.g. "document ETT size, attempts" - Denver protocol expects intubation attempts count and confirmation methods). Example given (ketamine documented, but no paralytic noted) covers a common omission[\[87\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L40-L48). Another: tube placement noted but no size/depth or CO₂ - also common error[\[87\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L40-L48). And capturing "2 attempts" if stated[\[86\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L30-L38) matches best practice (Denver doesn't explicitly list attempts in the PDF snippet, but it's standard QA). The weight (0.50) and threshold (0.90) indicate it's highly important[\[88\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L13-L20) - appropriate since missing any one element is significant, but the threshold allows one minor miss (maybe not critical) while still passing.  
\- **STEMI care (A-PRT2)** nails the key interventions: aspirin given, 12-lead performed/recognized, STEMI alert called, nitroglycerin (if not contraindicated)[\[89\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L9-L17)[\[90\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L28-L36). These align with Denver cardiac protocols: e.g. Protocol 3070 (STEMI Alert) expects early ASA, ECG interpretation, notification of cath center[\[91\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L38-L44). The inclusion even notes to exclude if a step was contraindicated and documented as such (allergy to aspirin)[\[90\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L28-L36)[\[92\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L32-L40) - good nuance. The threshold 0.85[\[93\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L13-L21) is a tad lower, implying if one of the steps is missed, it's still a fail (0.85 "Excellent" means essentially all critical steps done except perhaps one non-critical). Weight 0.50 gives STEMI equal importance to RSI in rubric. This makes sense: both are time-sensitive protocols with mandated steps.  
\- **Rubric context**: The rubric description explicitly calls out RSI, STEMI, and DOA as focus[\[94\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-PRT.yaml#L6-L14)[\[95\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-PRT.yaml#L16-L25). It also references "protocol-mandated steps must be documented or contraindication noted"[\[96\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-PRT.yaml#L24-L28), which is exactly what these benchmarks enforce. It's protocol-agnostic phrasing but clearly informed by local guidelines (e.g. "RSI must include sedative, paralytic, confirmation"[\[96\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-PRT.yaml#L24-L28) - matches Denver 1000; "DOA must include all four pronouncement elements"[\[96\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-PRT.yaml#L24-L28) - matches Denver 0050).

**Issues Found**:  
\- **Limited protocol coverage**: Only RSI and STEMI are covered explicitly. There are other protocols that might warrant tracking: for example, **Termination of Resuscitation (0051)** or **Field Pronouncement (0050)** - however, those are partly handled under A-CMP5. Another is **Stroke protocol** (last known well, stroke scale, alert) - but that is in A-STR rubric. **Trauma alerts** - handled in A-TRM3. **Pediatric respiratory or cardiac protocols** - partially via A-PED benchmarks. So actually, most critical protocols have their own rubric categories. Given that, A-PRT focusing on RSI and STEMI is fine. Perhaps consider if **Sepsis protocol** or **ROSC care protocol** need coverage, but those may be lower priority (and more clinical judgment than documentation; plus our synthetic scenarios may not target those yet).  
\- **Base contact documentation**: RSI often requires base contact if additional doses or if a parameter out of norm - but probably beyond scope of doc (and our scenario ground truths likely incorporate those if needed). No change needed; just noting base contact physician name for advanced procedures is good to document (though not explicitly in A-PRT1; presumably if base was called for RSI meds, that would be captured in narrative and should appear, but no explicit check - possibly could be part of A-PRT1 completeness or A-REF3 if treated as similar to refusal base contact). This is an edge case - if RSI is done under standing orders vs physician order. Denver allows RSI under protocol for medics, so base contact not required unless issues. No action.  
\- **Sedation post-intubation**: The concept in A-PRT1 mentions post-intubation sedation if mentioned[\[85\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L10-L18). The inclusion criteria explicitly include it: if narrative says they gave additional sedation/analgesia after tube, output should have it[\[85\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L10-L18)[\[86\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L30-L38). That's great because medics often forget to chart ongoing sedation; this benchmark will catch if AI misses it. No issue - just highlighting positive alignment with Protocol 1000's note that patient should be kept sedated post-intubation (protocol text likely implies it).  
\- **Example realism**: The provided examples are good, but could add one scenario: intubation attempt documented as failed in narrative and a rescue airway used, ensure output reflects attempt count and result. However, that might be too granular. Current examples suffice. For STEMI, example of missing STEMI alert is given[\[91\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L38-L44), and missing aspirin. Perhaps include "Output failed to mention 12-lead ECG at all" - though the example hints at that ("no STEMI pathway or escalation in output despite ST elevation evidence")[\[91\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L38-L44). That covers it.

**Recommended Changes**:  
\- \[ \] **Consider other protocol benchmarks or rubric expansion**: For completeness, we could propose new benchmarks for other critical protocols: e.g. _A-PRT3: Stroke Protocol_ (but we have A-STR rubric for that, so maybe redundant), _A-PRT4: Cardiac Arrest Protocol_ (check that CPR, shocks, meds followed algorithm - but that's more sequencing, which might be better in A-TMP or A-CAR rubric). Since those are covered elsewhere, it might be best not to overload A-PRT. A-PRT is effectively used for mixed-system protocols not covered by other rubrics. No immediate changes needed; just confirm that no glaring protocol documentation type is untested. One possible gap: **Behavioral protocols (6010/6015)** requiring documentation of IMC-RASS score, de-escalation attempts, etc. We do cover that in A-BHV1/2 for restraints and capacity, but not explicitly RASS documentation. Given Restraint Protocol documentation list includes "document RASS score"[\[97\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20A,care%20to%20emergency%20department%20staff), perhaps adding that detail to A-BHV1 (it already says "including IMC-RASS score" under documentation in protocol) - we should ensure our output in restraint cases contains it. We might quietly assume Medic Copilot would extract "patient was IMC-RASS +4" if in narrative. If not, we might add to A-BHV2 (capacity) or A-BHV1 criteria.  
\- \[ \] **Slight threshold tweak?** RSI benchmark is 0.90[\[88\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L13-L20); given how critical each element is, one could argue for 1.0. But allowing 90% gives a small margin (maybe if one minor detail missing). That's acceptable. STEMI at 0.85[\[93\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L13-L21) also effectively requires all major steps (85% threshold implies perhaps 1 of 6 minor items could slide). That's probably fine, as maybe they consider nitro optional if BP low (which would be documented as contraindicated rather than given - which the exclusion covers)[\[92\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L32-L40). In summary, thresholds seem clinically justified. No change.  
\- \[ \] **Augment A-PRT1 example**: Add one where intubation attempt count is explicitly in narrative and show expected output capturing it (they do mention it in inclusion and an example indirectly)[\[86\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L30-L38)[\[87\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L40-L48). E.g., _"Narrative: '2 intubation attempts made, airway secured on second attempt with 7.5 ETT at 22 cm' but output lists intubation success without number of attempts."_ This would reinforce that attempts must be documented, which is explicitly in criteria already.

### A-PED (Pediatric Documentation)

**Assessment**: Sound - covers the two highest-risk pediatric documentation issues (dosing and capturing peds details). Examples and thresholds are appropriate, just ensure coverage of edge cases (Broselow, neonates) in test cases.  
**Strengths**:  
\- **Weight-based dosing (A-PED1)** is addressed with zero tolerance for serious calc errors[\[98\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED1.yaml#L8-L16)[\[99\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED1.yaml#L22-L30). The benchmark demands that Medic Copilot catch any discrepancy in weight-based dose calculation. Example of 0.01 mg vs 0.2 mg epinephrine dose[\[98\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED1.yaml#L8-L16)[\[100\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED1.yaml#L38-L41) hits the classic 10x error scenario. The threshold is 0.95 (essentially no errors allowed aside from trivial rounding)[\[101\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED1.yaml#L13-L21)[\[99\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED1.yaml#L22-L30) and marked hard_gate - appropriate, since a single pediatric dosing error can be fatal. This aligns with protocol expectations that dosing be exact (and often double-checked). The Denver protocols emphasize careful pediatric dosing; our eval rightly treats such errors as critical.  
\- **Pediatric assessment completeness (A-PED2)** ensures that pediatric-specific info is documented: patient weight or Broselow color, APGAR scores for newborns, cap refill or other child-specific exam findings[\[102\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-PED.yaml#L16-L24)[\[103\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED2.yaml#L8-L16). This is key because general assessment benchmarks might not flag these pediatric details. The inclusion criteria explicitly mention weight/Broselow, APGAR, developmental findings[\[104\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED2.yaml#L28-L36). Denver protocol 8110 "Trauma in Pregnancy" even begins by noting Estimated Gestational Age for trauma patients[\[105\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=8110%20TRAUMA%20IN%20PREGNANCY%20Approved,EGA) - by analogy, in newborn care they specifically require APGAR at 1 and 5 minutes[\[106\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=mother%2C%20and%20assessed%20for%20breathing,minute%20APGAR%20scores). The benchmark's directive to capture APGAR if stated[\[107\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-PED.yaml#L24-L28) is directly backed by protocol (we see "Document 1- and 5-minute APGAR scores" in the OB protocol)[\[108\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=%E2%80%A2%20Document%201,30%20minutes.%20If%20delivered). The APGAR example (8 and 9 stated but output lacks it) is perfect[\[109\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L40-L48). Also, including Broselow tape color/weight is great, since Denver services often use Broselow for peds dosing (e.g. narrative "Broselow Yellow, ~18 kg" should appear).  
\- **Thresholds**: A-PED1 is effectively strict (0.95, hard gate)[\[101\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED1.yaml#L13-L21) - meaning even one dose calc error likely fails. A-PED2 is 0.90[\[110\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED2.yaml#L14-L22) - allowing a tiny margin (perhaps missing one minor detail) but expecting most pediatric info present. This reflects that missing an APGAR or weight is serious but maybe not as lethal as a dosing error, so a slightly lower threshold is acceptable.  
\- Examples are very realistic: Epi dose calc, Broselow, APGAR. They also include acceptable cases (0.195 vs 0.2 mg rounding is fine)[\[111\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED1.yaml#L32-L40), which is clinically sensible - tiny rounding differences won't affect outcome or protocol compliance.

**Issues Found**:  
\- **Newborn vs pediatric split**: The rubric lumps obstetric/neonatal with pediatric here conceptually, but note we also have A-OBS rubric for OB. APGAR appears in both A-PED2 and A-OBS1 (since APGAR is neonatal). In fact, A-OBS1 explicitly covers APGAR as well[\[112\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L8-L16)[\[109\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L40-L48). This is a bit overlapping: we should clarify that APGAR omissions would be caught by either rubric. It might be intentional redundancy, or perhaps A-PED2 was more for slightly older kids and A-OBS1 for newborn deliveries. Given APGAR is listed in both, it's fine as long as test cases use one consistently. Just be mindful not to double-count failure if both benchmarks apply (the system likely won't double-penalize since ground truth would categorize the scenario under one rubric).  
\- **No mention of pediatric** vital norms**: Not expected here (that's clinical judgment). E.g., whether Medic Copilot flags a HR of 160 as high for a toddler is out of scope (that's inference-time knowledge). So it's fine that we only test extraction and completeness.**  
**\-** No explicit test of Broselow vs actual weight**: The benchmarks assume narrative provides something. Perhaps add an example: "Narrative: 'Broselow color Yellow (~22 kg)' but output has no weight or Broselow mention." This would fit A-PED2. The criteria cover it**[**\[104\]**](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED2.yaml#L28-L36)**, just ensure at least one test case does.**  
**\-** Edge: Pediatric medication concentration**: Not directly tested, but if Medic Copilot mis-documents a pediatric dose unit (e.g. mg vs mg/kg), that would either fall under A-PED1 (if it leads to wrong calc) or A-FMT2 (if it's a format violation). For instance, if output wrote "Epi 0.1 mg/kg" instead of total mg, that might confuse documentation. Probably too granular to include as a separate fail; the main thing is the numeric value is correct. We can rely on format/schema checks for correct units (A-FMT2 covers units in numeric fields**[**\[113\]**](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FMT2.yaml#L28-L36)[**\[114\]**](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FMT2.yaml#L40-L48)**).**  
**\-** Protocol cross-ref\*\*: Denver peds protocols (like universal Peds distress, etc.) often require weight documentation. The rubric covers that. Also, neonatal resuscitation (3020) is partially covered by APGAR in OB rubric and presumably by capturing any interventions (though no specific benchmark for Neonatal algorithm steps - but that might be overkill for now).

**Recommended Changes**:  
\- \[ \] **Clarify APGAR duplication**: Decide whether APGAR omissions fall under A-OBS1 or A-PED2 to avoid confusion. Since APGAR is obstetric (newborn) and rubric A-OBS is specifically "Obstetric & Neonatal," perhaps leave APGAR primarily to A-OBS1. A-PED2's mention of APGAR could then be seen as overlapping. One approach: have A-OBS1 handle APGAR and immediate newborn care documentation, while A-PED2 focuses on older pediatric cases (weight, Broselow, pediatric exam). This is a nuanced distinction - practically, it might not matter as long as all scenarios are labeled correctly. Just note it in documentation to prevent double-flagging.  
\- \[ \] **Include a Broselow example** in A-PED2 explicitly. E.g., _"Narrative: 'Used Broselow tape, patient in Green zone (~35 kg), Epi dose per tape given' but output does not record patient weight or Broselow color."_ This would reinforce capturing weight info.  
\- \[ \] **Consider pediatric medication _preparation_ errors**: While A-PED1 catches calculation errors, if Medic Copilot were to hallucinate a wrong concentration or volume, that could be an issue. However, that strays into operational details beyond chart content. We likely skip this as it's not explicitly charted (the chart usually has just dose given, not how it was prepared).  
\- \[ \] **No threshold changes**: The current thresholds are clinically appropriate. Keep A-PED1 at effectively 1.0 (0.95 with hard gate)[\[101\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PED1.yaml#L13-L21) - pediatric dosing errors must be zero. A-PED2 at 0.90 is fine; if Medic Copilot misses one minor detail (say doesn't mention cap refill but got weight and APGAR), that's acceptable.

### A-CAR (Cardiac Arrest Documentation)

**Assessment**: Sound - addresses critical elements of cardiac arrest documentation completely. Just ensure ROSC timing and termination orders are captured (they are, via A-CAR1 and A-CMP5 interplay).  
**Strengths**:  
\- **Outcome documentation (A-CAR1)** is given top priority with a 0.95 threshold and hard_gate[\[115\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR1.yaml#L8-L16). If Medic Copilot fails to document whether the patient achieved ROSC or was terminated in the field, that's an almost-automatic fail. This reflects protocol: Denver 3000 (Medical Arrest) and 0051 (Termination) require clearly noting if ROSC occurred or if efforts stopped (including time). The example "ROSC achieved at 08:32 mentioned in narrative but not charted"[\[116\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR1.yaml#L36-L41) shows exactly what we want to catch. Also "termination called by medical control but output lacks pronouncement"[\[116\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR1.yaml#L36-L41) - again, major medicolegal gap if missing. It even expects **timestamp** of ROSC, noting that just saying "ROSC" isn't enough without time[\[116\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR1.yaml#L36-L41). Good attention to detail.  
\- **Arrest event details (A-CAR2)** ensure the narrative specifics of the resuscitation are not lost[\[117\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR2.yaml#L8-L16). This includes initial rhythm, shock count, drug administration, airway management - all key Utstein data points[\[118\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-CAR.yaml#L18-L26)[\[119\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR2.yaml#L9-L17). The examples are excellent: narrative lists "VFib, shocked x3, epi x2, intubated", but output just says "CPR performed"[\[120\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR2.yaml#L38-L45) - a sadly realistic scenario for bad documentation that this will flag. Also missing initial rhythm is explicitly called out[\[120\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR2.yaml#L38-L45). The threshold (0.85) and weight (0.40) indicate we expect most details but allow if one minor item is missed[\[121\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR2.yaml#L13-L21). That seems fair - e.g. if everything was documented except perhaps one dose time, that might still be acceptable clinically (though ideally all should be there).  
\- **Protocol alignment**: Denver's cardiac arrest protocol (3000) and Post-Arrest Care (3030) emphasize documenting shocks, meds, and outcomes for QA (and state reporting). The rubric critical requirements highlight ROSC/outcome, rhythm, shocks as MUSTs[\[118\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-CAR.yaml#L18-L26). This matches national Utstein template too.  
\- **Integration with other rubrics**: A-CAR works alongside A-CMP5 (pronouncement fields) and A-SFT (safety logic for termination criteria if any). For instance, A-CMP5 will ensure if field termination happened, the pronouncement time/physician are logged[\[45\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L28-L36). A-CAR1 ensures outcome (ROSC vs death) is noted, and A-REF3 could cover if base physician name was omitted (though A-REF3 is under refusals, we might not apply it to termination - instead, A-CMP5 covers physician name on pronouncement[\[45\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L28-L36)). So all pieces of arrest documentation are addressed.

**Issues Found**:  
\- **ROSC time vs just ROSC**: A-CAR1's example explicitly expects the timestamp of ROSC, not just that it happened[\[116\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR1.yaml#L36-L41). Denver 3000 protocol doesn't explicitly list "document ROSC time" in the snippet we have, but it's implied in practice and good documentation. We agree that including time is ideal. The benchmark will penalize if output says "ROSC achieved" without a time stamp (the example says that's not enough)[\[116\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR1.yaml#L36-L41). This is a high standard but a correct one for completeness. We should ensure ground truth cases include ROSC time so the evaluation expects it.  
\- **Termination base contact**: When medics terminate resuscitation, protocol 0051 requires base contact for authorization unless criteria met by standing order. The benchmark doesn't explicitly mention documenting the physician - but A-CMP5 does ("pronouncing physician name")[\[45\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L28-L36). We should verify that a scenario with termination would be evaluated by both A-CAR1 (checking outcome logged) and A-CMP5 (checking the four pronouncement fields) - likely yes. That covers it: outcome "field termination" should be stated and pronouncement elements should be filled (time, physician, method, agency)[\[45\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L28-L36).  
\- **Traumatic arrest differences**: Traumatic arrest documentation might differ (they often call death on scene quicker). The benchmarks here are generalized and fine. Traumatic arrest specifics (mechanism, no CPR if injuries unsurvivable) are more protocol and would reflect in narrative rather than structured data (except marking cause of arrest as trauma perhaps). Not necessary to split out - just note that A-CAR applies to both medical and traumatic arrests as needed. If needed, scenarios can be labeled accordingly, but documentation expectations (document outcome, rhythm if known, interventions done) apply equally.  
\- **Post-ROSC care**: No specific benchmark on whether post-ROSC vitals or interventions (cooling, etc.) were documented. However, A-CAR2 would cover if a ROSC was achieved but then output omitted that epinephrine was stopped or a BP improved, etc. It's a minor point. Perhaps not needed, as those are more clinical actions than documentation requirements (other than noting ROSC which A-CAR1 covers, and documenting any ongoing care which falls under general treatment documentation completeness).

**Recommended Changes**:  
\- \[ \] **Emphasize time documentation**: Possibly update A-CAR1 descriptions to explicitly say "must include timestamp when available" not just in example. It currently implies it ("ROSC time required")[\[116\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR1.yaml#L36-L41). We can add to critical_requirements: "ROSC or termination **time** must be documented" to reinforce that. This is a small wording tweak for clarity.  
\- \[ \] **No threshold changes**: 0.95 for outcome is good - essentially no tolerance for missing the outcome (which is correct)[\[122\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR1.yaml#L13-L21). 0.85 for details is fine - if they documented majority of interventions, they pass, missing too many fails. That aligns with importance.  
\- \[ \] **Add example (if not already)**: A scenario of a patient who never achieved ROSC and was pronounced with base contact. The output should say "No ROSC, terminated per Dr. X at 07:45." If output missed physician name, A-CMP5 catches it; if output missed outcome entirely, A-CAR1 catches it. Maybe ensure either A-CAR1 or A-CMP5 example covers that explicitly (A-CAR1's second example does mention base call and lack of pronouncement)[\[116\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR1.yaml#L36-L41). That's likely sufficient.  
\- \[ \] **Monitoring of ongoing CPR events**: This might be beyond scope, but consider if Medic Copilot should flag deviations like "epi given out of protocol timing" - that's more clinical performance than documentation. We rightly do not test that here. No change.

### A-REF (Refusal Documentation)

**Assessment**: Sound - extremely important rubric and it covers all critical aspects of refusal/AMA documentation as per protocol 0032[\[123\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20Requirements%20for%20Refusal%20%E2%80%A2,care%20unless%20standing%20order%20refusal)[\[124\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=%E2%80%A2%20Risks%20of%20refusal%20explained,candidate%20for%20an%20alternative%20disposition). Examples are excellent and threshold logic is appropriately strict.  
**Strengths**:  
\- **Risk explanation (A-REF1)** is treated as non-negotiable: threshold 1.0 (hard gate)[\[125\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF1.yaml#L14-L22) and weight 0.60, meaning if Medic Copilot fails to document that risks were explained and understood, it's an automatic fail. Denver's protocol explicitly lists "Risks of refusal explained" and "Patient understands risks" as required documentation[\[126\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=%E2%80%A2%20Confirm%20decision,care%20unless%20standing%20order%20refusal). The benchmark mirrors this[\[127\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF1.yaml#L8-L17)[\[128\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF1.yaml#L28-L36). Example given ("explained risks including death, output just 'refused transport'") is exactly the scenario we fear[\[129\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF1.yaml#L43-L48). This will catch a huge medicolegal hazard - not charting that you warned the patient.  
\- **Signature/Witness (A-REF2)** covers whether the refusal form was signed or a witness documented if not[\[130\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF2.yaml#L8-L16)[\[131\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF2.yaml#L28-L36). Protocol says "Signed refusal … if possible"[\[132\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=%E2%80%A2%20Patient%20reminded%20they%20may,candidate%20for%20an%20alternative%20disposition), and if not, medics usually note "patient refused to sign, witness John Doe". The benchmark requires that if such info is in narrative, it must appear in output[\[131\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF2.yaml#L28-L36). Threshold 0.85[\[133\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF2.yaml#L14-L22), weight 0.40 - slightly forgiving; presumably missing a witness name might drop score but not necessarily fail rubric if risk was documented (since rubric pass threshold is 0.95[\[134\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-REF.yaml#L13-L21) - actually rubric threshold is 0.95 overall, meaning effectively both A-REF1 and one of the others must pass high). That's reasonable: risk explanation is most critical, signature is second (if everything else is perfect but they forgot to note witness, that's still a serious issue though). Perhaps consider making signature threshold higher, but the current balance is likely fine.  
\- **Base contact (A-REF3)** ensures that if a physician was consulted, their name/advice is recorded[\[135\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF3.yaml#L8-L16)[\[136\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF3.yaml#L29-L37). Denver 0032 requires "Name of Base physician authorizing refusal unless standing order"[\[132\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=%E2%80%A2%20Patient%20reminded%20they%20may,candidate%20for%20an%20alternative%20disposition). A-REF3 enforces that with 0.95 threshold (almost all such cases must have it)[\[137\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF3.yaml#L14-L22). Weight is only 0.20, reflecting that not all refusals involve base contact (only high-risk ones do) but if it was mentioned, it's important. The example "spoke with Dr. Adams, output omits Dr. Adams"[\[138\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF3.yaml#L40-L44) is exactly a failure case. This is crucial not just for documentation but also for legal protection ("medical control agreed with our decision" must be recorded).  
\- **Focus on capacity**: The rubric guidelines mention capacity assessment explicitly[\[139\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-REF.yaml#L18-L26), and indeed the documentation requirements say "confirm decision-making capacity"[\[140\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20Requirements%20for%20Refusal%20%E2%80%A2,authorizing%20refusal%20of%20care%20unless). While no separate benchmark is labeled for capacity, A-REF1's inclusion hints at it ("if narrative describes capacity or base consulted… output must reflect discussion")[\[141\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF1.yaml#L30-L38). Essentially, if patient were not capacity, it wouldn't be a refusal case (they'd treat under implied consent). So A-REF rubric assumes capacity if refusal is allowed, and wants it confirmed in documentation. The guidelines require it documented[\[140\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20Requirements%20for%20Refusal%20%E2%80%A2,authorizing%20refusal%20of%20care%20unless), and Medic Copilot should include a note like "Patient alert and oriented, deemed capable of refusing." If the narrative states that, missing it might not be flagged explicitly except maybe as a "critical field omission" (A-UNC2) if we mark capacity as a critical field. Possibly we rely on SME review for that. However, since 0032 lists it, perhaps we should incorporate it: see **Recommended Changes**.

**Issues Found**:  
\- **No direct benchmark for capacity documentation**: As noted, capacity is needed in the PCR. If Medic Copilot fails to include that the patient was competent, that's a documentation gap. Currently, none of A-REF1/2/3 explicitly fails for that. We might cover it by treating it as part of risk explanation or as an **uncertainty omission** (since capacity is a critical precondition, leaving it unstated might be seen as silently omitted field). In fact, A-UNC2 could apply: it lists capacity_assessment as a critical field that should be flagged if absent[\[142\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L30-L38). Yes, A-UNC2 does mention capacity in inclusion[\[142\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L30-L38). So if narrative implied a capacity eval (or just by virtue of being a refusal case, capacity is needed), Medic Copilot should say something or at least mark unknown. If it doesn't, A-UNC2 would score it down. So capacity is indirectly handled by A-UNC2. Perhaps we could strengthen that link by ensuring refusal test cases also trigger A-UNC2 if capacity isn't documented. This is a bit indirect but okay.  
\- **Thresholds and rubric passing**: Rubric A-REF requires 0.95 to pass[\[134\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-REF.yaml#L13-L21). With weights 0.60, 0.40, 0.20 summing to 1.0, effectively to get 0.95 overall, A-REF1 must be perfect (or nearly, but it's hard_gate so it's either 1 or 0). So risk must be documented or entire rubric fails (good). If risk is documented, missing either signature or base could drop score: e.g. risk=1.0, signature=0.0, base not applicable (1.0) yields weighted score 0.60+0+0.20=0.80, failing rubric. So you really can't omit the signature either if it was needed, or base if applicable. In fact, to get ≥0.95, essentially A-REF1=1.0 and at least one of A-REF2/3 also near 1. This is appropriately strict. We might consider upping A-REF2's threshold from 0.85 to 0.95 too, to signal that if signature was mentioned it must be there, but since rubric calc already likely fails if it's missing, that might be fine.  
\- **Example coverage**: The examples are thorough: each benchmark has multiple realistic scenarios[\[129\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF1.yaml#L43-L48)[\[143\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF2.yaml#L38-L41)[\[138\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF3.yaml#L40-L44). One thing to consider adding: a case of a _high-risk refusal requiring base contact_. For instance, "post-naloxone patient refusing transport" - protocol strongly urges base contact in such cases (in fact Denver protocol says base contact strongly recommended for high risk like that)[\[144\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=High%20Risk%20Patients%20Base%20Contact,Documentation%20Requirements%20for%20Refusal). If ground truth includes base contact and advice, output better have it (A-REF3). Possibly we have such a test already. If not, that would be a good one (ensures interplay of all three benchmarks: patient initially unresponsive, given Narcan, now awake and refusing - medic calls base and explains risks, etc.).

**Recommended Changes**:  
\- \[ \] **Explicitly document capacity in outputs**: Encourage in rubric notes or evaluator guide that the assistant should include a statement of capacity for refusal cases. Perhaps modify A-REF1 concept to "… does not include that risks were explained **and/or that patient had decision-making capacity**…"[\[145\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF1.yaml#L8-L16). This would clarify that capacity assessment omission falls under the same severe category. Alternatively, create a new benchmark (A-REF4) just for capacity, but that might be overkill since capacity is essentially a prerequisite noted in guidelines. I lean toward treating it within A-REF1's scope, since 0032 lists it in the same breath as explaining risks[\[140\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20Requirements%20for%20Refusal%20%E2%80%A2,authorizing%20refusal%20of%20care%20unless)[\[146\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=%E2%80%A2%20Risks%20of%20refusal%20explained,care%20unless%20standing%20order%20refusal). So: add "confirm capacity" to A-REF1 inclusion criteria and examples (e.g. add example: "Narrative: 'Patient alert, oriented, deemed capable of refusal' but output does not mention patient capacity.").  
\- \[ \] **Slight increase A-REF2 threshold**: Consider 0.95 instead of 0.85[\[133\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF2.yaml#L14-L22). Rationale: If a narrative explicitly says "refusal form signed" or "patient refused to sign, witness present," failing to record that is almost as critical as risk documentation from a legal standpoint. The form signature is your legal safeguard. Currently, if A-REF2 is 0.0, rubric fails anyway in most cases, but making it 0.95 would reflect that it's essentially expected in 100% of applicable cases. However, since weight is 0.40, even at 0.85 threshold, if it's missing it drags rubric score significantly. Either way, likely fine. This is optional; the rubric as-is will fail if signature missing (as shown above).  
\- \[ \] **Add high-risk refusal scenario** (if not already in test set): As mentioned, a refusal after treatment (e.g. woke from hypoglycemia or overdose) where base contact is made. This will test all pieces - capacity (the medic might question it), risk explanation, base physician name, witness if patient refuses signature, etc. The evaluation harness can then verify Medic Copilot handles the most complex refusal scenario correctly.  
\- \[ \] **Ensure alignment with A-UNC**: For capacity, ensure that if Medic Copilot were to omit capacity and A-REF somehow didn't catch it, A-UNC2 would (it lists capacity as critical)[\[142\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L30-L38). This is already the case. We should double-check that refusal scenarios are indeed marked so that A-UNC2 triggers if capacity is absent. Likely yes, since ground truth for refusals could label capacity as a required field (especially if narrative had it). This is more on implementation side.

### A-STR (Stroke Documentation)

**Assessment**: Sound - covers all key stroke documentation elements per protocol. Perhaps consider adding NIHSS if ever dictated, but generally LAMS/CPSS are more likely in prehospital. No major gaps identified.  
**Strengths**:  
\- **Stroke scale documentation (A-STR1)** ensures that any stroke assessment score or neurological exam findings mentioned are captured[\[147\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR1.yaml#L8-L16)[\[148\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR1.yaml#L28-L36). Denver stroke protocol (4030) requires a stroke scale (they commonly use CPSS or LAMS in prehospital) and specific findings (facial droop, arm drift, speech) to be documented. The benchmark explicitly lists these: if narrative says "LAMS 4" or describes exam positives, the output must reflect them[\[147\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR1.yaml#L8-L16)[\[148\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR1.yaml#L28-L36). The example of output only saying "possible stroke" without actual findings is exactly the documentation lapse we want to catch[\[149\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR1.yaml#L40-L44). Threshold 0.90 (weight 0.50)[\[150\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR1.yaml#L14-L22) means missing a bit of detail might still barely pass, but most info should be there. That's fair - e.g. if they documented the scale but forgot to list one specific symptom detail, could still be 0.9.  
\- **LKW time and stroke alert (A-STR2)** are rightly treated as critical: threshold 0.95, hard_gate[\[151\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR2.yaml#L14-L22). "Last Known Well" (onset time) is perhaps the single most important piece of stroke data for determining treatment eligibility, and the protocol expects it documented if known. Likewise, if a stroke alert was called to the hospital, that must be in the report. A-STR2 will fail if either of those is omitted when present in narrative[\[152\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR2.yaml#L8-L17)[\[153\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR2.yaml#L26-L34). The examples reflect this: narrative gives a LKW time and says stroke alert called, but output lacks them[\[154\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR2.yaml#L40-L47). That's a major issue - this benchmark will catch it. Weight 0.50 ensures it heavily impacts rubric.  
\- **Focus areas vs protocol**: The rubric focus lines call out exactly these points: stroke scale score, LKW, stroke alert, plus neuro exam findings[\[155\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-STR.yaml#L16-L24). This aligns with Denver's acute stroke protocol which emphasizes documenting last known well and performing a stroke scale (FAST, CPSS or RACE) and making early hospital notification (Stroke Alert). The critical requirements echo protocol: "MUST document scale if stated, MUST capture LKW time if provided, MUST include alert if done"[\[156\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-STR.yaml#L24-L32). Perfect.  
\- **Examples and Acceptable Deviations**: It's noted that different scale names are fine if findings equivalent[\[157\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-STR.yaml#L18-L25), which is good because Medic Copilot might standardize (e.g. if narrative says "Cincinnati positive," output might list components or just say "Stroke scale positive"). Acceptable to consider synonyms. Also allows LKW given as relative time ("2 hours ago") instead of exact - that's okay as long as it's captured[\[158\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-STR.yaml#L22-L28). The rubric is reasonable here.

**Issues Found**:  
\- **No mention of NIHSS**: NIHSS is rarely done in prehospital (usually just hospital), so not an issue. They cover common prehospital scales (LAMS, CPSS, FAST, RACE). That's fine. If a scenario had an NIH Stroke Scale from an RN on scene or something, it would still be caught by "stroke scale score stated must be documented." So fine.  
\- **Threshold strictness**: 0.95 for LKW/alert means essentially both must be present if known. That is correct - missing LKW or alert is a major patient care issue (could delay tPA or thrombectomy). So we agree. 0.90 for scale/neuro means minor omissions possibly tolerated. That's acceptable since sometimes medics might not explicitly quantify a scale but document the findings ("slurred speech, left arm drift") - which if output captures, that's fine. If output missed one minor sign but got the gist, that might still get ~0.8-0.9. That's okay.  
\- **Potential overlap with A-TMP or A-CMP**: LKW time is also a temporal data point. If Medic Copilot documented a wrong time format, A-FMT2 could catch format errors. If it omitted LKW, A-STR2 covers it. No conflict, just synergy. Similarly, calling a Stroke Alert is somewhat like a protocol step - we chose to put it here rather than A-PRT, which is fine.  
\- **Measuring exam completeness**: A-STR1 expects any neuro findings stated to be present. It doesn't explicitly measure if output recorded negative findings (though if narrative says "no facial droop" and output omitted that, technically that's a negation issue and A-NEG would catch if it turned it positive or left it unknown). The negation rubric would catch polarity errors. If Medic Copilot just left out mentioning a negative, that might not be flagged (since ground truth might not list it as required to explicitly say "no X" unless we label it). Typically, medics document stroke scale negatives as "0" or "normal" for those components. Our eval harness probably isn't requiring explicit mention of each negative - that's fine (scope: not every implicit normal needs stating). So this is acceptable - we are focusing on what _was_ stated.  
\- **No specific test for blood glucose** in stroke rubric - but presumably in scenarios medics will have checked glucose, and if output missed it, A-FCT1 (vitals extraction) would catch it as a vital omission. Yes, A-FCT1 includes glucose[\[11\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT1.yaml#L10-L18). Good.

**Recommended Changes**:  
\- \[ \] **None major**: The A-STR benchmarks are well-conceived. Just ensure that test cases exist for both a positive stroke scale scenario and maybe a negative one (to ensure the system doesn't hallucinate a score). Possibly include a case where narrative says "Stroke scale: 0 (normal)" - output should reflect exam normal (and not trigger failure since it did document it as normal). Given our focus is extraction fidelity, this should be fine as long as output says something equivalent (or explicitly "no deficits" etc.).  
\- \[ \] **Add minor example**: Could add an acceptable example in documentation: "Ground truth: LKW unknown - output marks LKW as unknown. This should not fail" (Rubric already notes if narrative explicitly says unknown, that's acceptable[\[159\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR2.yaml#L32-L40)). Maybe include that in examples or acceptable notes so it's clear to evaluators that "unknown LKW" is okay if captured as such.  
\- \[ \] **Emphasize stroke alert communication**: Perhaps update A-STR2 concept to mention hospital notification: it says "stroke alert notification" already[\[160\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-STR.yaml#L8-L16). It's clear. No change.  
\- \[ \] **NIHSS mention (optional)**: We could note in rubric guidelines that prehospital providers typically use simpler scales, so NIHSS would rarely appear. No need to complicate eval with that.

### A-TRM (Trauma Documentation)

**Assessment**: Sound - covers critical trauma documentation needs: neuro assessment (GCS), interventions, and trauma team activation. Some fine-tuning on threshold for GCS might be considered (we might want near 100% compliance), but current settings are reasonable.  
**Strengths**:  
\- **GCS/Neuro and Mechanism (A-TRM1)**: This benchmark ensures that if the narrative provided a Glasgow Coma Scale or described LOC/mental status or mechanism of injury, the output includes them[\[161\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM1.yaml#L8-L16)[\[162\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM1.yaml#L29-L37). Trauma protocol (8000 General Trauma Care) absolutely requires GCS (or at least mental status) and mechanism be documented. The example shows omission: "GCS 13, head lac from fall" in narrative but output with no GCS is a fail[\[163\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM1.yaml#L40-L45). Also mechanism example "MVC rollover…" but output lacked MOI[\[163\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM1.yaml#L40-L45) - unacceptable per protocol (which uses mechanism as triage criteria). Threshold 0.90[\[164\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM1.yaml#L15-L23) means we expect essentially all crucial info - maybe allowing one piece (e.g. if they gave GCS components E4V4M5, and output only wrote 'GCS 13', that might still pass, which is fine). Weight 0.50 gives this a big impact.  
\- **Critical interventions (A-TRM2)**: This captures if any life-saving trauma procedure was performed (tourniquet, wound packing, needle decompression, pelvic binder, etc.) it must appear in output[\[165\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM2.yaml#L8-L16)[\[166\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM2.yaml#L28-L36). This is spot-on - trauma protocols (e.g. 1120 Tourniquet Procedure, or trauma protocols 8010/8020) require these documented including times. The example "Tourniquet applied at 12:00 but output no mention"[\[167\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM2.yaml#L38-L41) or "Needle decompression done, output just says 'chest injury treated'"[\[168\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM2.yaml#L38-L43) highlight deadly omissions. The threshold 0.95, hard_gate[\[169\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM2.yaml#L14-L22) reflects zero tolerance - if a medic actually did a procedure and the AI missed it, that's a critical fail. Agreed: missing documentation of a tourniquet or chest decompression is huge (could lead to confusion at hospital or duplication of risky procedures). Weight 0.50, so it's as important as GCS in rubric.  
\- **Trauma alert/hospital notification (A-TRM3)**: Ensures that if a "Trauma Alert" or similar activation was called (or should be called), the output includes it[\[170\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM3.yaml#L8-L16)[\[171\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM3.yaml#L29-L37). Many EMS systems have criteria for trauma alerts, and if narrative says it was activated, it's crucial for continuity to document ("trauma team activated" etc.). The benchmark example covers: narrative said "Trauma alert activated, ETA 5 min" but output omitted it[\[172\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM3.yaml#L40-L44). That's a significant communication failure. Threshold 0.95[\[173\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM3.yaml#L15-L23) means it must be there, and weight 0.25 is a bit lower, acknowledging not every trauma requires an alert (only more severe). But if it happened, it should be recorded. This aligns with protocol: Denver doesn't explicitly list "document trauma alert" in the text we saw, but obviously if one is called, it should be noted.  
\- **Documentation nuance**: A-TRM1 notes that mechanism details should be included. Acceptable deviations mentioned in rubric: GCS can be total or components[\[174\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-TRM.yaml#L18-L26), which is good (either "GCS 13" or "E4V4M5" - both convey it). They also allow minor differences in phrasing mechanism, which is fine (e.g. "fall from 20 feet" vs "20ft fall" - either is okay as long as mechanism info is there).  
\- The rubric critical requirements mirror protocol expectations: "GCS MUST if stated" (yes, trauma triage uses GCS < 13 as criterion)[\[175\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-TRM.yaml#L26-L34); "life-saving interventions MUST appear"[\[175\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-TRM.yaml#L26-L34) (yes, crucial); "tourniquet time MUST be captured if documented"[\[175\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-TRM.yaml#L26-L34) (Denver tourniquet procedure likely says record time applied - indeed medics always note that). So those are explicitly enforced.

**Issues Found**:  
\- **GCS threshold**: 0.90 allows some leeway, but arguably GCS (if given) is so fundamental that missing it should almost always fail. However, since weight is 0.50, even if output got 0 on A-TRM1, rubric score would be at most 0.5; combined with others likely failing, rubric fails. Perhaps we could set threshold 1.0 for A-TRM1 to emphasize no tolerance for missing GCS. But if narrative said a very detailed neuro exam and output captured most but not the numeric GCS, do we fail them entirely? Possibly yes - GCS is often used as shorthand, but if they described "confused, eyes open to voice, localizes pain" (which is GCS 12) and output maybe said "confused" but didn't calculate GCS, that might currently be a fail by A-TRM1. Actually, if narrative has GCS components, that counts as stating GCS essentially. We might allow equivalently describing it. The rubric does accept descriptors as fulfilling it (it says "or describes LOC for a trauma patient"[\[176\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM1.yaml#L30-L37) triggers it - meaning if they described neuro status, that should be documented). So output could either give GCS or the equivalent narrative; either should count. As long as Medic Copilot includes some neuro assessment (e.g. "patient confused, localizes pain"), that should pass A-TRM1. So 0.90 threshold is okay to allow slight wording differences. We just need to ensure the evaluator logic counts descriptive neuro exam as success even if numeric GCS isn't explicitly written, provided content is there. Given normalization formula is identity[\[177\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM1.yaml#L18-L26) and descriptions say 0.90 = "key neuro findings present"[\[178\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM1.yaml#L22-L28), likely yes.  
\- **Intervention list coverage**: A-TRM2 lists tourniquet, wound packing, needle decompression, pelvic binder, chest seal as examples. Are there others? Possibly traction splint for femur fracture - not exactly life-saving but important. They didn't list it, but one could consider it. However, traction splint omission is less critical than a tourniquet omission (it's painful but not immediately life-threatening if missed in chart). So okay to focus on major ones. If anything, one might add "cricothyrotomy" but that's a form of advanced airway - which likely would be documented under RSI (if done under RSI procedure) or at least noted. Cric is rare and would be major; but we can assume if narrative said it and output missed it, A-TRM2 would catch as a life-saving procedure omission. It said such interventions "must appear in Treatment section"[\[166\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM2.yaml#L28-L36) - yes, cric would count. It's not listed but falls under major invasive procedures. Possibly add "surgical airway" in concept text to be safe.  
\- **Trauma alert vs tiered activation**: In Denver, "Trauma Alert" might be a Level 1 vs Level 2 etc. The benchmark just looks for any mention. That's fine. It covers "level 1 trauma called" as in example[\[172\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM3.yaml#L40-L44). If narrative didn't mention any alert, we don't expect output to invent it, so no issue. If medics transported without calling alert, no penalty as nothing in ground truth. Good.  
\- **Timeline of interventions**: Not directly tested here, but A-TMP and A-CAR cover ordering (like no shocks documented before rhythm etc.). Not needed here.  
\- **Combine with other rubrics**: Mechanism is also checked in A-NEG if negated, or A-CMP if omitted? Actually, A-TRM1 covers mechanism if stated. If mechanism wasn't stated, no fail. If mechanism was obvious (like a trauma scenario would have one, presumably narrative always has one). The trauma protocol likely expects medics to note mechanism; if the narrative didn't have it, that's more a scenario design issue. But in real world sometimes mechanism info isn't available. In any case, if scenario lacks it, we wouldn't apply A-TRM1. If scenario has it and output missed it, fail by A-TRM1. That works.

**Recommended Changes**:  
\- \[ \] **Add "cricothyrotomy" to A-TRM2 concept/examples** as one of the critical interventions that must be documented if performed. It's rare but falls in same category (life-saving invasive procedure). E.g. _"Narrative: 'Unable to intubate, performed cricothyrotomy' but output has no mention of cric."_ This would ensure we cover surgical airway. Given rubric reference, it might be covered by RSI rubric if it's considered part of airway management. However, RSI rubric wouldn't apply to a cric scenario (that's a failed airway, different procedure). So adding it here makes sense.  
\- \[ \] **Consider traction splint or tourniquet time details**: Maybe ensure scenario for tourniquet includes a time, since A-TRM2 inclusion highlights capturing time[\[166\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM2.yaml#L28-L36). Possibly we already have example where narrative says time. If not, we should test that.  
\- \[ \] **Threshold adjustments**: Possibly raise A-TRM1 to 0.95 to enforce GCS documentation more strictly. But because descriptive documentation counts, 0.90 is okay. No strong change needed. If any, maybe raise to 0.95 to parallel other MUSTs. Given weight 0.50, a 0.90 vs 0.95 likely won't change pass/fail much. I lean to keep as is.  
\- \[ \] **Trauma alert example**: Already present. We could add an acceptable deviation example: If patient was transported to trauma center without explicit "alert" and none was called, that's fine (no false fail). But that's self-evident by inclusion criteria (only apply if narrative explicitly says alert was called)[\[179\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM3.yaml#L28-L36). So fine.

### A-OBS (Obstetric & Neonatal Documentation)

**Assessment**: Sound - targets critical documentation for deliveries and OB emergencies. Just ensure overlap with A-PED/A-REF is managed (e.g. obstetric refusal of transport if it occurs, but that's rare). Current benchmarks cover APGAR, delivery times, and pregnancy details well.  
**Strengths**:  
\- **Neonatal info (A-OBS1)** is comprehensive: it checks APGAR scores, newborn condition, and any neonatal resuscitation steps in narrative are reflected[\[112\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L8-L16)[\[180\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L28-L36). Example: narrative gave APGAR 8/9 and baby status, output omitted - that fails[\[181\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L40-L45). Also if narrative described interventions (stimulate, O₂, etc.) and output just says "delivery occurred," that fails[\[181\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L40-L45). This aligns with Denver OB protocol which explicitly says "Document 1- and 5-minute APGAR"[\[108\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=%E2%80%A2%20Document%201,30%20minutes.%20If%20delivered) and to note neonatal care (drying, stimulation etc.). Threshold 0.95, hard_gate[\[182\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L14-L22) means essentially you cannot miss APGAR or newborn status - correct, as this is standard data pediatric teams expect on handoff.  
\- **Maternal pregnancy details (A-OBS2)** ensures that if the patient is pregnant or has OB complications, all pertinent info is documented: gestational age (weeks), gravida/para, multiple gestation, and any complications like bleeding, hypertension, etc.[\[183\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS2.yaml#L8-L16)[\[184\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS2.yaml#L28-L36). Example: narrative "35 weeks G3P2, possible preeclampsia" but output just says "pregnant" - that fails[\[185\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS2.yaml#L40-L43). Also postpartum example: placenta delivered, EBL ~500 mL stated, output omitted - that fails[\[186\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS2.yaml#L40-L44). This is directly tied to Denver OB protocols (e.g. 7000 and 7010): they list gestational age, presence of multiple gestation, and postpartum hemorrhage details as important to manage. Weight 0.50, threshold 0.90[\[187\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS2.yaml#L14-L22) means most details must be present, but maybe missing one minor aspect might still pass - e.g. if they noted pregnancy and twins but forgot to note G/P, score might be ~0.8, failing. So effectively, we want all crucial details.  
\- **Focus**: rubric calls out APGAR, delivery time, gestational age, complications[\[188\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-OBS.yaml#L16-L24) - all must-haves per protocol (e.g. time of birth should be documented for any field delivery; protocols typically say note delivery time). The critical requirements reiterate those: APGAR must be captured, delivery time must appear, gestational age must be documented if provided[\[189\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-OBS.yaml#L24-L32). Yes, Denver protocol doesn't explicitly say "record delivery time" in the snippet, but obviously it's important (and likely in narrative ground truth). This rubric ensures none of these fall through.  
\- **Integration**: APGAR also appeared in A-PED, but by having it here, we double-cover neonatal which is fine. Behavioral childbirth refusals or unusual cases are beyond scope (rare someone in labor refuses, but if so, that's covered by refusal rubric anyway).

**Issues Found**:  
\- **Delivery time documentation**: The rubric says if baby was born in field, "delivery time MUST appear"[\[190\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-OBS.yaml#L26-L32). A-OBS1 examples mention APGAR and condition, but do not explicitly mention if missing delivery timestamp is tested. Perhaps the ground truth for a delivery scenario will include the time of birth, and if output omits it, that should count under A-OBS1's scope (newborn status incomplete). It might be worth adding an example: "Baby delivered at 14:32" in narrative but output didn't record time - to illustrate that requirement[\[181\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L40-L45) (the last example does hint at this: "Birth time: delivered at 14:32 must include time in output"[\[191\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L40-L44) - yes it's there!). Good. That example covers it.  
\- **Overlap with A-PED2**: APGAR is mentioned in both. Likely, for a field delivery scenario, both A-OBS1 and A-PED2 would apply - which is redundant. Probably the intention is A-OBS deals with births (mom and neonate in same call) whereas A-PED covers pediatric illness/injury. We should ensure that in evaluation, a birth scenario is labeled for A-OBS rubric and not double-evaluated by A-PED2. It might be wise to not apply A-PED to newborn scenarios. This is more of a test planning detail but important to avoid confusion.  
\- **Postpartum and obstetric complications**: The examples mention postpartum hemorrhage and placenta status[\[192\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS2.yaml#L38-L44). That's great. If narrative says placenta delivered or heavy bleeding, output must note it. Denver 7010 (Obstetrical Complications) likely expects noting if placenta delivered and estimating blood loss. This benchmark covers that. Perhaps ensure there's also coverage of **pregnancy trauma** (there is protocol 8110 Trauma in Pregnancy, requiring gestational age noted - A-OBS2 would catch if narrative gave EGA but output missed it[\[193\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=2026%20Estimated%20Gestational%20Age%20)). Yes, A-OBS2 includes pregnancy details in any context. Good.  
\- **No explicit mention of** treatment given to mother\*\* like magnesium for eclampsia or oxytocin for hemorrhage - but those are medications, so if they were in narrative and omitted, A-FCT (med extraction) or A-TRM2 (if considered critical intervention?) would catch. Actually, administering Mg in eclampsia is protocol, if narrative said it and output missed it, that's like a medication omission. If we implement A-FCT2 (med extraction) as recommended, that would catch it. For now, not explicitly covered unless we view it as critical (Mg for eclampsia is life-saving for seizures, but it's still a med extraction error more than an OB documentation category error). I think focusing A-OBS on data fields (age, G/P, etc.) is fine and let med omissions be handled elsewhere.

**Recommended Changes**:  
\- \[ \] **Clarify rubric scope**: Note that A-OBS applies to any scenario involving labor, delivery, or pregnancy-specific issues. That includes trauma in pregnancy (8110) for capturing EGA, and medical OB emergencies. Perhaps add an example of an obstetric emergency without delivery: e.g. "36 weeks, seizure -> eclampsia" scenario - output should document pregnancy and possibly that it's eclampsia. But if narrative said it, output presumably would. Actually, eclampsia would likely be documented as impression, which should be captured by A-FCT4 (impression match) or at least not lost. So maybe not needed here.  
\- \[ \] **Avoid double evaluation**: Ensure that a field delivery scenario is primarily evaluated by A-OBS and not A-PED for APGAR. We can assign test cases appropriately (this is more an internal note). Possibly mention in rubric guidelines that neonatal documentation is here, not in pediatric rubric, to guide scenario assignment.  
\- \[ \] **Add minor example**: Perhaps one where twins are delivered and output should list both babies' info. The inclusion mentions that for twin deliveries, both neonates must be documented individually[\[180\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L28-L36). We could include an example: "Twin delivery: Baby A and Baby B with respective APGARs - output only documented one baby" as a failure. Actually, the example list does have: "Twin delivery… both must be captured"[\[181\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L40-L45). Great, it's there.  
\- \[ \] **No threshold change**: 0.95 for neonatal info is right - cannot miss APGAR or baby status. 0.90 for pregnancy details is fine - ideally all present, but maybe if one minor detail like exact gravida parity was off, might still pass (though in example they treat missing G/P as fail). Maybe consider 0.95 as well to enforce nearly everything? But current weighting will likely fail if major detail missed. It's okay.  
\- \[ \] **Coordinate with A-REF**: In the rare event a pregnant patient refuses transport (maybe minor trauma, insists on not going), that would fall under refusal rubric. A-OBS wouldn't have special handling except ensuring pregnancy details were documented. Our evaluation should be fine; just a note that multiple rubrics can apply in some scenarios (e.g. a pregnant trauma patient who refuses - we'd have A-TRM, A-OBS, and A-REF possibly all in play). That's complex but should be okay if ground truth is thorough. No specific change, just awareness.

### A-BHV (Behavioral/Psychiatric Documentation)

**Assessment**: Sound - addresses the two crucial aspects in behavioral cases: documenting any restraints/sedation, and documenting capacity/hold status. Aligns with protocol and legal requirements. Perhaps add explicit mention of RASS score documentation in output as that is protocol, though arguably that falls under detailing restraint use which A-BHV1 covers implicitly.  
**Strengths**:  
\- **Restraint/Sedation documentation (A-BHV1)** is treated as critical: threshold 1.0, hard_gate[\[194\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L16-L24). If the narrative indicates physical restraints were applied or chemical sedation given, the output must mention it. This is absolutely required by protocol and law - EMS must document any restraint (type, time, monitoring) and any sedative given for behavioral control. The examples reflect common omissions: medic secured patient with soft restraints but output said nothing[\[195\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L43-L48); medic gave Versed 5 mg IM for agitation but output omitted it[\[195\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L43-L48). Both are egregious and will be caught. Notably, the inclusion also says if narrative describes post-restraint monitoring ("checked q15, circ intact"), that should be captured[\[196\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L30-L38). This ties to Denver Restraint Protocol: it explicitly requires documenting limb circulation checks and patient status during restraint[\[197\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=greater%20risk,RASS%20score)[\[198\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=2.%20Efforts%20to%20de,care%20to%20emergency%20department%20staff). So A-BHV1 not only checks that restraints/sedation are noted, but implicitly that ongoing monitoring isn't entirely omitted. The rubric weight 0.50 ensures it significantly affects score.  
\- **Capacity/Consent documentation (A-BHV2)** covers whether the patient's decision-making capacity or legal hold status is documented[\[199\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV2.yaml#L8-L16)[\[200\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV2.yaml#L28-L36). Behavioral emergencies often involve either implied consent (patient lacks capacity) or an involuntary hold (5150/M1 hold). If narrative indicates the patient was not competent or was placed on a hold, the output must reflect that. Example: narrative says "patient on 5150 hold, transported involuntarily," output said nothing about it[\[201\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV2.yaml#L38-L41) - that's a fail. Also "deemed incompetent due to psychosis, unable to refuse care" in narrative but not in output[\[202\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV2.yaml#L38-L42) - fail. This aligns with legal requirements: if we treat without consent, we need to document why (lack capacity or hold). Denver protocol 6000 defines criteria for placing someone on a mental health hold and stresses documentation of cause[\[203\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=match%20at%20L665%20%E2%80%A2%20Refer,the%20encounter%2C%20including%20the%20circumstances)[\[204\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=6000%20PSYCHIATRIC%2FBEHAVIORAL%20PATIENT%20PROTOCOL%20Approved,and%20willing%20to%20initiate%20a). A-BHV2 ensures Medic Copilot doesn't omit those critical context points. Threshold 0.90[\[205\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV2.yaml#L14-L22) indicates we expect almost all such info, but if one minor nuance is missing maybe still okay - though likely if capacity is not mentioned, it'll drop a lot. Weight 0.50 - as important as restraints.  
\- **Protocol alignment**: The rubric mentions documenting restraint use, sedation doses, capacity assessment, and any legal hold (5150)[\[206\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-BHV.yaml#L16-L24)[\[207\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-BHV.yaml#L26-L33). This matches Denver's Restraint Procedure documentation list (we saw: document facts justifying restraint, RASS score, de-escalation attempts, type of restraints, patient condition during, etc.)[\[97\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20A,care%20to%20emergency%20department%20staff). Our benchmarks cover the big pieces: presence of restraint/sedation and presence of capacity/hold status. They don't explicitly mention RASS score in output, but presumably if narrative gave "IMC-RASS +4", output should include it as part of documenting the scenario. A-BHV1 inclusion does say to capture if provided (in the protocol excerpt, RASS is included under documentation requirements)[\[97\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20A,care%20to%20emergency%20department%20staff). We might implicitly expect it under "description of facts justifying restraint including RASS" - if narrative gave it, output should. If output omitted the RASS value, arguably that's missing detail - the current checks might not flag it unless we treat it as part of capacity or as a vital sign (RASS isn't exactly vital, but it's an assessment score). Perhaps minor gap, see below.

**Issues Found**:  
\- **RASS score documentation**: As noted, Denver's protocol expects the IMC-RASS score to be documented whenever restraints or chemical sedation are used[\[97\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20A,care%20to%20emergency%20department%20staff). Our evaluation doesn't explicitly check for RASS presence. If narrative says "IMC-RASS +4 (combative)", and output describes the patient as combative and needing restraints but omits the numeric score, is that a fail? Possibly not under current rules, since the information ("patient combative") is conveyed. However, some EMS agencies treat documenting the actual score as important for QA. It might be too granular to force the numeric value - if the output at least indicates severe agitation, that's arguably acceptable. But maybe we want it. Given A-BHV1 inclusion says "responder must document actions and that patient was at IMC-RASS +3/+4"[\[196\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L30-L38) (this is hinted by "including IMC-RASS score" in the protocol text), perhaps incorporate a note that if a RASS value was stated it should appear. This could be folded into A-BHV1. That said, failing just for missing the number if behavior is described might be harsh. We can leave it as is (the rubric doesn't explicitly say "score must be present", just says if it was documented in narrative and omitted entirely, that's an issue of omission of a fact - so A-FCT might catch it as an extraction failure of a numeric if ground truth labels it). Possibly okay.  
\- **De-escalation attempts**: Protocol also requires documenting efforts to calm before restraining[\[198\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=2.%20Efforts%20to%20de,care%20to%20emergency%20department%20staff). Our benchmarks don't directly check if output noted de-escalation. For instance, narrative: "verbal de-escalation attempted, patient continued to fight, so restrained" - if output doesn't mention we tried verbal, that's omission of a detail. Currently, no benchmark flags that explicitly. However, A-BHV1 inclusion says "if narrative describes attempts to de-escalate, it should be captured as per CMS"[\[196\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L30-L38). So presumably, if ground truth includes that line as something important, and output omitted it, we could consider that part of failing A-BHV1 (since not all facts around restraint were documented). It's subtle. It might not be automated well unless done via LLM judge (to see if output included a mention of attempts). Possibly out of scope to enforce explicitly. But at least our inclusion criterion nods to it. This might be acceptable to leave as a known slight gap unless we create a new benchmark. Probably okay given time.  
\- **Interactions with A-REF**: If a behavioral patient refuses, that's unusual (if they lack capacity, they can't refuse; if they have capacity and are just upset, not really an emergency maybe). Not a big overlap in practice. If someone on a psychiatric hold tries to refuse, it's not valid. So A-REF likely wouldn't apply with A-BHV at same time (unless capacity was debated). So no conflict. If a patient was sedated or restrained, they lack capacity, so no refusal form needed - implied consent. So rubrics cover distinct scenarios.  
\- **Examples**: A-BHV1 examples cover both physical and chemical restraints, and even note the combination scenario (both used - must document both)[\[195\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L43-L48). Good. They also mention "monitoring: restraints checked q15" should be captured[\[208\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L44-L48), which is important for CMS. A-BHV2 examples show hold status and capacity. Perhaps could add an example of an implied consent due to intoxication without formal hold: e.g. "patient deemed incapable due to intoxication, treated under implied consent" - but they have one ("unable to refuse care" example)[\[201\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV2.yaml#L38-L41) which covers that. So that's fine.  
\- **Threshold logic**: A-BHV1 is threshold 1.0[\[194\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L16-L24) - absolutely must have if narrative did. A-BHV2 is 0.90[\[205\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV2.yaml#L14-L22) - if output missed one nuance (like it said patient incompetent but didn't mention the hold paperwork, or vice versa), maybe partial credit. That's okay. And rubric passing threshold is 0.90 overall[\[209\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-BHV.yaml#L12-L19). That effectively means you can't miss much of either. If A-BHV1 fails (0), rubric score max 0.50 which fails. If A-BHV1 pass and A-BHV2 slightly low, might still pass rubric if not below 0.90. But likely any big omission fails. This is acceptable risk balance - perhaps rubric threshold could even be 0.95 to be stricter, but 0.90 is alright since maybe not all behavioral calls have sedation or hold (the rubric presumably only counts those benchmarks when applicable).

**Recommended Changes**:  
\- \[ \] **Include RASS score note**: Possibly update A-BHV1 concept to "…fails to document that restraints were applied or sedatives given (including any agitation score if provided)" to signal that if a numeric agitation score was explicitly in narrative, it should appear. This is a minor textual tweak to emphasize completeness.  
\- \[ \] **No new benchmark needed** for de-escalation documentation, but maybe ensure our LLM judge in A-BHV1 prompt looks for mention of attempts if present. This might already be covered by hybrid evaluator checking key phrases. Just an internal consideration for implementation.  
\- \[ \] **Maintain strict stance**: No threshold relaxation. If anything, consider making rubric threshold 0.95 or even 1.0, because these are truly medicolegal critical. But 0.90 might be to allow one category slightly off if another fully met. Given weight equal, if one is perfect and other is 0.80, rubric would be 0.40+0.40=0.80 fail. To pass ≥0.90, basically one must be full and the other at least partial high. That's fine. Maybe leave at 0.90; it already implies essentially both aspects documented.  
\- \[ \] **Add an example or note about documentation of** law enforcement involvement\*\*: Sometimes medics note if PD applied handcuffs or if patient was placed on an M1 hold by a clinician or officer. Our inclusion covers "if hold, document physician name if stated" etc. Perhaps ensure an example scenario includes "geographical" - in Denver, typically police or a mental health professional places a hold (medics document it, but they themselves don't "write 5150" - that's California term though used in rubric). The example does "patient on 5150 hold"[\[201\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV2.yaml#L38-L41) which covers it. So fine.

### A-UNC (Uncertainty Handling)

**Assessment**: Sound - addresses both major uncertainty failure modes (hallucinating data and failing to flag missing critical info). This rubric is forward-looking and important for trust. No major clinical content issues; just ensure it's clear what fields are considered "critical" for omissions.  
**Strengths**:  
\- **Hallucinated data (A-UNC1)** is given a hard zero-tolerance[\[210\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC1.yaml#L10-L18)[\[211\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC1.yaml#L22-L30). If Medic Copilot outputs any value not supported by the narrative, that's an automatic fail (threshold 1.0, hard_gate)[\[212\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC1.yaml#L14-L22). This is crucial for medicolegal accuracy - making up an allergy ("NKDA" when patient didn't say so)[\[213\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC1.yaml#L38-L41) or adding vitals that never existed is absolutely unacceptable. The examples are spot-on: listing allergies the patient didn't mention[\[213\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC1.yaml#L38-L41), inventing a second set of vitals out of thin air[\[213\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC1.yaml#L38-L41), giving a weight when none was provided[\[214\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC1.yaml#L39-L42), or populating home meds that weren't stated[\[214\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC1.yaml#L39-L42). These cover a range of plausible hallucinations. This benchmark will heavily penalize any attempt by the AI to "fill in" missing info on its own, which is exactly what we want to prevent.  
\- **Silent omissions (A-UNC2)** ensures that if a critical field's information was truly not available, the output doesn't just leave it blank without any note[\[215\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L8-L16)[\[142\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L30-L38). Essentially, for things like refusal risk, pronouncement time, capacity, etc., if narrative lacked them, the AI should at least mark unknown or flag it. The inclusion list explicitly names high-liability fields: risks_explained (refusal), pronouncement_time (DOA), capacity_assessment (behavioral), consent, and other critical protocol fields[\[142\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L30-L38). If these are absent in narrative and output simply omits them instead of indicating "unknown" or "unable to obtain," that's a failure. This pushes the AI to be transparent about gaps. Threshold 0.90[\[216\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L14-L22) means majority of critical gaps must be handled, but maybe if one minor one wasn't, could still pass - but given the weight (0.40) and rubric threshold 0.95[\[217\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-UNC.yaml#L10-L18), effectively it needs to flag almost all such cases.  
\- **Overall scope**: The rubric description clearly differentiates these two failures: no invented facts, and flagging unknowns[\[218\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-UNC.yaml#L6-L14)[\[219\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-UNC.yaml#L22-L28). This is aligned with best practices: document "unknown" rather than guessing, and never chart something that wasn't said or observed. The critical requirements underline "Never invent values" and "Flag critical absent fields"[\[219\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-UNC.yaml#L22-L28) - exactly what an auditor wants to see.  
\- **Examples**: For hallucinations, we covered them - very realistic for an overzealous AI (we saw GPT sometimes output NKDA on its own in testing - this will catch that)[\[213\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC1.yaml#L38-L41). For silent omissions, the examples list scenarios: refusal narrative lacked risk discussion and output left that section blank without noting anything[\[220\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L44-L49), DOA case missing pronouncement time and not marked unknown[\[220\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L44-L49), capacity in behavioral case missing with no comment[\[221\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L46-L49), RSI missing paralytic dose without flag[\[222\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L46-L50). These examples hit the intended points and overlap with other rubrics intentionally: it's possible an output might fail A-REF1 and A-UNC2 for the same issue (no risk noted _and_ no "unknown" flag - essentially just blank). That's okay since those are critical errors anyway. The overlapping ensures it doesn't slip by.

**Issues Found**:  
\- **Defining "critical field"**: The list in A-UNC2 inclusion is clear[\[142\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L30-L38), but we should ensure this list stays updated with any new fields we consider critical. Right now: refusal risks, pronouncement time, capacity/consent, and "critical protocol fields." That last part is broad - presumably meaning things like "stroke LKW" or "STEMI alert" could count. Do we explicitly label those? Possibly ground truth could tag them. For now, we trust scenario labeling to decide what's critical. The ones given are good. No obvious omissions in that list: perhaps add **allergy status** as critical? Actually, if narrative truly didn't mention allergies, output leaving allergies blank is fine as "unknown." But many agencies default to "No allergies noted" or ask patient and then mark NKDA if none. The hallucination test forbids guessing NKDA, so the AI should either mark allergies field as null or state "Unknown" if not asked. A-UNC2 might apply: allergies are important but not exactly "high-liability" unless they have one. Usually, if allergy is unknown, leaving blank might be interpreted as not asked. Maybe not make that critical - it's important but not as dangerous as missing refusal risk. So okay.  
\- **Interaction with other rubrics**: As noted, A-UNC has overlap potential. For example, if the AI fabricates a vital sign, A-FCT1 might not catch it (because ground truth had no second vitals to compare - A-FCT1 only checks if something stated was mis-extracted, not if extra was invented). But A-UNC1 _will_ catch it[\[223\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC1.yaml#L26-L34)[\[213\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC1.yaml#L38-L41). Good. If AI omits a critical field entirely, other rubrics like A-REF or A-CMP might fail them too, but A-UNC2 specifically focuses on whether they flagged it as unknown vs leaving silent. Example: if narrative never provided a pronouncement time, A-CMP5 expects one of the four pronouncement elements - but if none given, maybe ground truth wouldn't include a time either. In that case, Medic Copilot can't conjure it; we'd want them to mark unknown or "not documented in narrative". If output just leaves it blank, A-UNC2 fails but A-CMP5 might also fail because pronouncement_time field is null. We have to be careful - if the medic truly didn't state a time, is it fair to fail the AI for not having it? We solve by expecting an explicit "unknown" flag to satisfy completeness. That's what A-UNC2 enforces. So yes, ground truth for DOA scenario would likely label pronouncement_time as "missing but should be flagged." The harness then checks if output indicated unknown. This is a bit complex but doable. The interplay is okay. It essentially forces AI to say "pronouncement time: Unknown" if none was given, which is actually a good practice.  
\- **No threshold issues**: A-UNC1 is effectively pass/fail - correct. A-UNC2 threshold 0.90 is fine because if two critical fields were silently omitted, likely score goes to 0.0 anyway (depending how scoring is defined - if it's fraction of omissions flagged, and two omissions both unflagged might result in 0.0). With weight 0.40, rubric pass threshold 0.95[\[224\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-UNC.yaml#L12-L19), basically you can't miss any critical omissions either or rubric fails. So rubric is practically requiring perfection on hallucinations and near-perfection on flagging. That's acceptable given these are meta-quality issues that ensure trust.

**Recommended Changes**:  
\- \[ \] **Clarify "flagging" in A-UNC2**: We should define what counts as flagging a missing field. Likely, if output explicitly says "Unknown" or "Not documented" for that field, that is acceptable[\[225\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L36-L43). If output just leaves it blank or null with no comment, that's a fail. Perhaps in evaluation guidelines, specify acceptable ways to denote unknown (so Medic Copilot or post-processor knows how to represent it). Possibly they plan to literally put a value like null or an "unknown" string. That's more on format, but since we evaluate meaning, either is fine if it clearly conveys unknown.  
\- \[ \] **Add example of correct behavior**: Maybe in documentation, note a positive example such as: _"Narrative does not state pronouncement time; output: 'pronouncement_time: unknown' (this is acceptable - field acknowledged as unknown)."_ to contrast the failure examples. This will guide understanding of what the pass condition is.  
\- \[ \] **Expand critical field list if needed**: Think of any other fields: Possibly **Patient identity info** - not applicable, AI wouldn't guess a name hopefully. **Outcome of call** (transport vs non-transport) - but if narrative didn't say, AI shouldn't assume - but it might have to categorize as part of output schema. Actually, disposition is always needed. If narrative was silent on transport, AI might presume transported unless refusal. Perhaps not an issue - medics always document disposition. If AI omitted it, format check would fail since schema expects it. So covered. No change.  
\- \[ \] **No threshold change**: keep as is. Possibly raise rubric threshold from 0.95 to 1.0 because really we want no hallucinations and no critical omissions. But if A-UNC2 ended up 0.9 and A-UNC1 1.0, rubric 0.95 passes. That means they flagged most missing data but maybe missed flagging one thing and still passed rubric. Should that be allowed? Perhaps - if one small thing (like forgot to mark unknown allergy status) but everything else was perfect, maybe that's okay. Setting rubric to 1.0 would require absolute perfection (no hallucinations and every critical gap flagged). As an SME, I'd prefer perfection here, but it might be harsh. 0.95 gives a tiny buffer. Given weight distribution (0.60 vs 0.40), to hit 0.95 with a slightly imperfect A-UNC2: e.g. if A-UNC1=1.0 and A-UNC2=0.8, rubric = 0.6+0.32=0.92 fail. If A-UNC2=0.9, rubric=0.6+0.36=0.96 pass. So basically they can miss flagging maybe one out of ten fields (if we treat 0.90 as 90% flagged) and still pass. That's an edge scenario. I'm okay with 0.95 rubric as is.

## Denver Protocol Gap Analysis

| Protocol | Key Documentation Requirement | Current Coverage in Eval | Gap? | Priority | Action Recommendation |
| --- | --- | --- | --- | --- | --- |
| **0032 - Refusal** | \- Risks explained to patient&lt;br&gt;- Patient capacity confirmed&lt;br&gt;- Base contact physician name if required&lt;br&gt;- Signed refusal or witness name | **Covered:** A-REF1 (risks)[\[145\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF1.yaml#L8-L16), capacity indirectly via A-UNC2[\[142\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L30-L38), A-REF3 (base MD)[\[135\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF3.yaml#L8-L16), A-REF2 (signature)[\[130\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF2.yaml#L8-L16). | **No major gap** (capacity not standalone) | High | \- Ensure capacity is explicitly documented (tie into A-REF1/A-UNC2)[\[140\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20Requirements%20for%20Refusal%20%E2%80%A2,authorizing%20refusal%20of%20care%20unless)[\[142\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L30-L38).&lt;br&gt;- Perhaps raise A-REF2 threshold to 0.95 so signature omission is never acceptable. |
| **0050 - Field Pronouncement** | \- Pronouncement time&lt;br&gt;- Pronouncing physician name&lt;br&gt;- Pronouncement method (base order vs protocol)&lt;br&gt;- Agency notified (coroner) | **Covered:** A-CMP5 checks time, physician, method, agency all present[\[45\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L28-L36). Base contact aspect also by A-REF3 if applicable. | **No gap** | High | \- No change: A-CMP5 threshold 1.0 forces all 4 elements[\[226\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L14-L22). Reinforce in docs that "method" includes noting if via standing order or physician[\[45\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L28-L36). |
| **0051 - Termination of Resusc.** | \- Base contact for termination (unless criteria met)&lt;br&gt;- Time of termination&lt;br&gt;- Family informed (often) | **Covered:** Outcome/time via A-CAR1[\[115\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR1.yaml#L8-L16) and A-CMP5 (fields)[\[45\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L28-L36); base contact by A-CMP5 (method/MD). Family informed not explicitly tested. | **Minor gap:** no check on documenting family informed | Medium | \- Consider including "family informed" note in narrative but not critical to automate. Could be SME manual review item.&lt;br&gt;- Ensure termination scenarios are evaluated by A-CAR1 and A-CMP5 (they are). |
| **1000 - RSI (Intubation: Oral)** | \- Indication for RSI&lt;br&gt;- Pre-oxygenation performed&lt;br&gt;- Sedative drug and dose&lt;br&gt;- Paralytic drug and dose&lt;br&gt;- ETT size and depth&lt;br&gt;- Confirmation methods (EtCO₂ required)&lt;br&gt;- # of attempts&lt;br&gt;- Post-intubation sedation/management | **Covered:** A-PRT1 hits all these except maybe indication explicitly[\[85\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L10-L18)[\[86\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L30-L38). It mentions preoxygenation and indication conceptually, and checks sedative, paralytic (doses), ETT size/depth, EtCO₂ confirmation, attempts count, post-intubation meds[\[86\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L30-L38). | **No major gap.** Might not explicitly verify indication documented, but usually narrative provides context. | High | \- Ensure scenario narrative includes indication and pre-oxygenation so AI can document it (though not explicitly scored, it's good documentation). Possibly accept if those are not separately charted as long as everything else is.&lt;br&gt;- A-PRT1 threshold 0.90 seems okay; consider 1.0 since missing any element is serious (but it does allow one minor omission) - keep for now. |
| **3000 - Cardiac Arrest** (General ALS) | \- Document initial rhythm&lt;br&gt;- All interventions with times (shocks, meds, airway)&lt;br&gt;- ROSC occurrence and time or termination&lt;br&gt;- CPR times (no flow time) - often via device auto-record, not narrative&lt;br&gt;- Who resuscitation handed off to if terminated on scene | **Covered:** Initial rhythm, shock count, meds via A-CAR2[\[117\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR2.yaml#L8-L16); ROSC and time via A-CAR1[\[115\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR1.yaml#L8-L16); termination time via A-CMP5[\[45\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L28-L36). CPR quality/times not explicitly evaluated (would be device data). Handoff on termination (coroner) not explicitly, but "agency notified" is part of pronouncement fields[\[45\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L28-L36). | **Minor gap:** No check for documenting CPR interruptions or quality (likely out of scope). Otherwise covered. | Low | \- No eval addition needed for CPR quality (beyond scope). Possibly include in narrative for completeness but not score.&lt;br&gt;- Emphasize in A-CAR2 that all listed interventions should have some documentation (which it does)[\[227\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR2.yaml#L28-L36). |
| **3010 - STEMI** (ACS Protocol) | \- 12-lead ECG performed and interpreted&lt;br&gt;- ASA 324 mg given (if no allergy)&lt;br&gt;- NTG given (if BP >90 and no contraindications) or documented why not&lt;br&gt;- IV access, O₂ as needed (routine care)&lt;br&gt;- STEMI Alert called to hospital with ETA | **Covered:** A-PRT2 checks ASA, 12-lead, STEMI alert, nitro[\[89\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L9-L17)[\[90\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L28-L36). O₂ and IV are routine - medics usually do and chart, but eval does not specifically check (could be considered minor omissions if not documented; not critical to eval unless absent and clinically needed, which ground truth likely wouldn't allow). | **No major gap.** If Nitro withheld due to contraindication, rubric doesn't fail (exclusion)[\[92\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L32-L40). O₂/IV not explicitly checked but low impact. | Medium | \- No change needed. Perhaps incorporate IV/O₂ into scenario but not scored.&lt;br&gt;- A-PRT2 already accounts for contraindications properly (no false fail if nitro held for reason)[\[92\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT2.yaml#L32-L40). Continue to ensure ground truth notes contraindications so AI isn't penalized. |
| **4030 - Stroke** (Acute CVA) | \- Document stroke scale (Cincinnati/FAST or LAMS) findings&lt;br&gt;- Document **Last Known Well time** (exact or approx)&lt;br&gt;- Blood glucose checked (to rule out hypo) - medics always do&lt;br&gt;- Stroke Alert to hospital if indicated&lt;br&gt;- If tPA contraindications noted (perhaps beyond EMS scope to document all) | **Covered:** A-STR1 (stroke scale & neuro findings)[\[147\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR1.yaml#L8-L16); A-STR2 (LKW time, stroke alert)[\[228\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR2.yaml#L8-L16). Glucose is a vital - if output missed it, A-FCT1 would catch (pain/glucose included as "clinical measurements")[\[11\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT1.yaml#L10-L18)[\[13\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT1.yaml#L38-L46). tPA contraindications usually not fully assessed by EMS, so N/A. | **No gap.** Evaluation hits all critical doc elements. | High | \- No changes. Possibly ensure scenario always includes a LKW (so we test that) and an alert if applicable. Check that if narrative says "LKW unknown," output marks it unknown to satisfy A-UNC2 (critical field absent flagged)[\[159\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR2.yaml#L32-L40)[\[142\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L30-L38). |
| **6000 - Psychiatric/Behavioral** (General) | \- Document patient's mental status/capacity&lt;br&gt;- If patient on mental health hold (M1/5150), document that and who authorized it&lt;br&gt;- If law enforcement involved, document their role (e.g. handcuffs)&lt;br&gt;- If patient refuses assessment/transport but is not capacity, treat under implied consent (document lack of capacity) | **Covered:** A-BHV2 covers capacity and hold status[\[200\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV2.yaml#L28-L36). Law enforcement involvement: not explicitly but presumably would be in narrative (could be documented as part of hold or restraints). If handcuffs used, medics usually defer to police - A-OBS? Actually "Transport of handcuffed patient (6020)" exists but eval doesn't explicitly check that is documented. Could be a gap if AI failed to mention PD restraints. But A-BHV1 covers restraint if medics did it; if only PD applied cuffs, AI should at least note patient was handcuffed by PD (that detail might be lost if not explicitly prompted - slight gap). | **Minor gap:** Not explicitly checking documentation of LE-involved restraints. | Low | \- If possible, include a note in scenario/narrative when PD handcuffs are present and expect AI to mention it (e.g. in narrative). Could use A-BHV1 or A-UNC2 if not captured (unclear, since technically not EMS-applied restraint). Probably low priority; rare scenario in documentation evaluation. No new benchmark, just SME awareness. |
| **6010 - Agitated/Combative** | \- Document de-escalation attempts&lt;br&gt;- Document IMC-RASS score before sedation/restraint&lt;br&gt;- Document medication given for sedation (dose, route)&lt;br&gt;- Document physical restraint applied (type) and position&lt;br&gt;- Document reassessment every 5-15 min (vitals, limb circulation) | **Covered:** A-BHV1 ensures any restraint or sedative used is documented[\[229\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L8-L16). It also expects mention of monitoring (it explicitly says include q15 checks if in narrative)[\[196\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L30-L38). RASS score: not explicitly scored, but narrative giving it and output omitting might be seen as missing detail (extraction gap). De-escalation attempts: narrative might have it; output omission not directly flagged except as part of context (could be minor). Vitals reassessment: A-SFT4 covers repeat vitals after high-risk interventions, which would include after sedation or restraint (e.g. "no post-sedation vital signs" would trigger A-SFT4)[\[73\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT4.yaml#L38-L46). Yes, A-SFT4 examples mention after physical restraints, no reassessment is a fail[\[82\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT4.yaml#L39-L43). | **Minor gap:** Not explicitly ensuring the RASS score is transcribed if provided. De-escalation attempts documentation not enforced. | Medium | \- Potentially incorporate RASS in A-BHV1 checks (as above). But given sedation/restraint presence is the main thing, missing the numeric score is secondary.&lt;br&gt;- Consider adding to A-BHV1 prompt: ensure if RASS value spoken, it's included (guidance rather than new test).&lt;br&gt;- De-escalation attempts: could be noted in guidelines but not auto-tested. Rely on narrative/LLM to include if mentioned. |
| **6015 - Post-Sedation** | \- Document continued monitoring: airway, SpO₂, ECG, BP&lt;br&gt;- Document effect of sedation (e.g. patient calmer) | **Covered:** A-SFT4 (missing repeat vitals after sedation)[\[73\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT4.yaml#L38-L46). If AI fails to document any post-sedation reassess, it fails A-SFT4. Effect of sedation (patient behavior) - not explicitly tested, but if narrative said "calmed down", output omitting it is minor. Could fall under completeness but not critical. | No major gap | Low | \- No separate action. A-SFT4 and A-BHV1 collectively handle this (vitals and presence of sedation documented). The qualitative "patient calmer" is nice to have, but not critical to auto-test. |
| **7000 - Childbirth/OB Emergencies** | \- Document gravidity/para (GxPx)&lt;br&gt;- Document if multiple gestation (twins) expected&lt;br&gt;- Document complications like preeclampsia signs, bleeding&lt;br&gt;- If delivery: time of birth, gender of baby, APGAR at 1 & 5 min, neonatal interventions&lt;br&gt;- Document placenta delivered and EBL (if postpartum) | **Covered:** A-OBS2 covers G/P, multiples, complications, EBL, etc.[\[184\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS2.yaml#L28-L36). A-OBS1 covers delivery specifics: time, APGARs, neonatal status[\[112\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L8-L16)[\[180\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L28-L36). These exactly align with protocol expectations (as gleaned from protocol and general OB practices)[\[230\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=mother%2C%20and%20assessed%20for%20breathing,Do%20not%20pull%20cord)[\[231\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=%E2%80%A2%20If%20the%20perineum%20is,EMS%20resources%20to%20provide%20care). | No gap | High | \- No changes. Ensure scenarios test both undelivered OB emergency (e.g. hemorrhage) and delivered case. A-OBS benchmarks handle both via respective triggers. |
| **8000 - Trauma General** | \- Document Mechanism of Injury (even if obvious)&lt;br&gt;- Document GCS (or mental status) for trauma patients&lt;br&gt;- Document vital signs trends&lt;br&gt;- Document major exam findings (e.g. distal neuro status in extremity injuries) | **Covered:** Mechanism & GCS via A-TRM1[\[161\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM1.yaml#L8-L16). Vitals trends - if any trend issue, A-TMP2 covers pre/post changes but that's more treatments. If output missed a trauma vital sign extraction, A-FCT1 covers it. Major exam findings: not explicitly except if life-threatening (trauma rubric focuses on critical interventions rather than every injury). Minor injuries not documented wouldn't fail unless considered incomplete assessment - but we have no direct check for missing minor exam items. | **Gap (minor):** Not verifying that every injury is documented - but that's arguably beyond scope (the AI might summarize). As long as critical ones are there, it's okay. | Low | \- No new benchmark; accept that minor exam details may not all be tested. The focus remains on critical data. Possibly in future, an "assessment completeness" (A-CMP4) could check that if multiple injuries were mentioned, output captured them. But given complexity, low priority. |
| **8010 - Traumatic Arrest** | \- If no signs of life and non-survivable injury, may pronounce - document justification (e.g. "injuries incompatible with life")&lt;br&gt;- If resuscitation attempted, follow 3000 plus mechanism notes&lt;br&gt;- Document whether transport or field pronouncement (and time) | **Covered:** Outcome via A-CAR1 (even if medical vs trauma)[\[115\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CAR1.yaml#L8-L16). Mechanism via A-TRM1[\[232\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM1.yaml#L26-L34). If pronounced on scene, A-CMP5 ensures pronouncement documentation[\[45\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L28-L36). Justification (injuries) - not explicitly required by eval; if narrative said "decapitation present" and output omitted it, that might slip by unless considered part of mechanism or exam. That detail should appear (for completeness and legal record). We have no explicit check for documenting the presence of obviously fatal injury, but arguably if narrative said it, it's a fact and missing it is an extraction failure of a detail. Possibly not flagged unless we had a specific test. | **Minor gap:** No direct check for documenting evidence of obvious death (like rigor, decapitation). But if not documented, likely doesn't affect structured data beyond outcome. | Low | \- Could add a note for scenario labeling: if obvious death signs were stated, ensure the AI outputs something acknowledging it. Hard to autoscoring except via LLM semantic check. Low priority - human SME can verify final output if needed. Given the eval's scope, probably not adding a benchmark for it now. |
| **8110 - Trauma in Pregnancy** | \- Document pregnancy and gestational age in any trauma involving a pregnant patient&lt;br&gt;- Tilted positioning or other pregnancy-specific care (not documentation per se, but actions)&lt;br&gt;- Document fetal movement if known (usually not in prehospital) | **Covered:** By A-OBS2 - if narrative says patient is pregnant X weeks, output must note it[\[184\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS2.yaml#L28-L36). It's a "critical detail" because it changes management. The eval will catch if AI fails to mention pregnancy status or gestation in a trauma case. (Also A-TRM1 would catch mechanism and GCS, but pregnancy part is via OB). | No gap | High | \- No change. Ensure any pregnant trauma scenario is evaluated by both trauma and OB benchmarks (which it will - likely scenario will be tagged for both rubrics). This double coverage is desirable to ensure pregnancy is not missed amid trauma details. |

## Enhancement Backlog

### Critical Priority

These enhancements address clear safety or medicolegal risks not currently fully covered by the evaluation:

| Enhancement | Related Benchmark(s) | Rationale |
| --- | --- | --- |
| **Implement Medication Extraction Benchmark** - Ensure all medications stated in narrative (name, dose, route) appear in output. Example failure: narrative "Morphine 4mg IV given" but output missing morphine. | _New_ A-FCT2 (to be created)[\[10\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-FCT.yaml#L16-L24) | Currently, no benchmark flags missing documented meds unless they tie into protocols (RSI/STEMI) or safety (overdose)[\[10\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-FCT.yaml#L16-L24). Med omissions can lead to billing errors and gaps in care handoff. This benchmark would fill that gap. **Priority: Critical**, as uncharted meds (e.g. narcotics given) pose legal questions. |
| **Define A-TMP3 (Protocol Sequence Order)** - e.g. verify RSI steps or cardiac arrest algorithm order are correct (no shock after ROSC, etc.). | A-TMP (placeholder)[\[22\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-TMP.yaml#L32-L38)[\[23\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP3.yaml#L9-L17) | Temporal logic within protocols (especially complex ones) is not fully tested due to placeholder A-TMP3[\[30\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP3.yaml#L2-L10). For patient safety and QA, ensuring steps occur in proper order is key (e.g. sedation _before_ paralysis in RSI, defib before epi in VF arrest). **Priority: Critical**, given potential patient harm if sequence is mis-ordered in documentation (which could reflect actual care error). |
| **Enforce Capacity Documentation in Refusals** - update evaluation to fail if a refusal has no note of patient capacity (unless implicitly clear). | A-REF1, A-UNC2[\[145\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF1.yaml#L8-L16)[\[142\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L30-L38) | While protocol 0032 requires capacity documentation[\[140\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20Requirements%20for%20Refusal%20%E2%80%A2,authorizing%20refusal%20of%20care%20unless), currently capacity might slip by if not explicitly flagged. This enhancement makes it explicit: a refusal without a "patient alert and oriented" note (or similar) is incomplete. It's medicolegal critical to show patient was competent. **Priority: Critical** (protects against lawsuits in refusals). |

### High Priority

High-impact improvements that close important gaps or improve evaluation strictness for significant documentation areas:

| Enhancement | Benchmark(s) | Rationale |
| --- | --- | --- |
| **Add Contradictory Evidence Check** - If narrative evidence contradicts output (e.g. output says "no X" but evidence span says "has X"), ensure it's flagged. | A-EVD3 (to define)[\[33\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-EVD.yaml#L24-L32)[\[34\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-EVD3.yaml#L9-L17) | Although A-NEG covers negation misinterpretation, an explicit evidence-based check adds robustness. E.g. ground truth can mark a contradiction and eval ensures AI flagged it. This closes the loop on evidence trust. **High priority** for documentation integrity (especially for audits where narrative vs structured data conflicts). |
| **Restraint Documentation Details** - Encourage/require inclusion of RASS score and de-escalation attempts if provided in narrative. Possibly via LLM prompt emphasis or minor benchmark extension. | A-BHV1[\[196\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L30-L38)[\[97\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20A,care%20to%20emergency%20department%20staff) | Denver protocol requires documenting RASS and de-escalation for restraints[\[97\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20A,care%20to%20emergency%20department%20staff)[\[198\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=2.%20Efforts%20to%20de,care%20to%20emergency%20department%20staff). Ensuring the AI carries those details if present will fully meet protocol. While missing them is less critical than missing the restraint entirely, it's important for QA. **High priority** due to liability around use-of-force documentation. (Could be implemented as stricter LLM judge criteria under A-BHV1). |
| **Ensure Twin/Newborn Multi-patient Documentation** - If narrative has twins or multiple newborns delivered, eval should verify each neonate's data is documented. | A-OBS1[\[180\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L28-L36) | The current example lists this, but we must implement test logic for it. Handling multiple patients in one narrative is complex, but at least ensure AI lists Baby A and Baby B separately if both born. Missing one baby's info is high impact. **High priority**: It's rare, but a big documentation error if it occurred. |
| **Medication Contraindication Rationale** - If AI administers a med despite contraindication, ensure output notes the rationale (e.g. "given per Base order despite allergy"). Possibly check via LLM if such scenario. | A-SFT2 (LLM judge nuance)[\[71\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT2.yaml#L28-L36)[\[84\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT2.yaml#L38-L41) | Right now A-SFT2 fails if a contra med given unflagged[\[233\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT2.yaml#L26-L34). We can enhance the LLM judge to pass if output explicitly documented the override with approval. This encourages good documentation of rule-bending when necessary. **High priority** for realism - medics occasionally give contra meds under direction, and AI should not be penalized if it notes the proper justification. |

### Medium Priority

Improvements that add nuance or cover less common cases, enhancing completeness but with lower criticality:

| Enhancement | Benchmark(s) | Rationale |
| --- | --- | --- |
| **General Assessment Completeness** - Define benchmarks (A-CMP2-4) for missing standard exam elements in Dispatch/Response/Arrival/Assessment sections. | A-CMP2-4 (placeholders)[\[54\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-CMP.yaml#L33-L41) | While core sections and critical fields are covered, having checks for e.g. missing _any_ Arrival details (if narrative had scene info) would tighten completeness. E.g. if narrative mentions a long extrication delay and output omitted it - a Response completeness fail. Medium priority as these are often lower risk omissions, but affect report quality. |
| **Sepsis/Shock Protocol Documentation** - Possibly add a benchmark for documentation of sepsis alerts or shock index if we have such scenarios. | _(New benchmark?)_ | We have no specific sepsis documentation checks. If synthetic data includes sepsis (e.g. lactate, sepsis alerts), a benchmark could ensure those are captured. Medium priority because it's time-sensitive like STEMI/Stroke. However, may not be needed if scenarios don't cover it extensively. |
| **Allergy Noted vs NKDA** - Possibly treat an explicitly stated "NKDA" in narrative as a fact to document (some PCRs have checkbox). We do cover allergies present, but not explicitly scoring if NKDA was said and output didn't record it. | A-ALL1[\[52\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-ALL1.yaml#L30-L38)[\[53\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-ALL1.yaml#L41-L48) | If a patient says "no allergies" and output leaves allergies blank, technically that's fine; but ideally output should mark "NKDA". A-ALL1 says it's not a failure if NKDA is correctly reflected[\[234\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-ALL1.yaml#L40-L43). To encourage thoroughness, we could warn if NKDA was spoken but not documented. Medium priority (mostly a completeness nicety, not safety issue). |
| **Trauma Iterative Exam Documentation** - If narrative lists multiple injuries, ensure AI didn't compress away something major (e.g. only documented the worst injury). Perhaps a soft check via LLM for thoroughness. | _LLM judgment in A-TRM1?_ | This is more for report quality than safety. For instance, patient with broken arm and laceration - if AI only mentioned the fracture, that's incomplete. This could be addressed by an LLM judge prompt: "Did output cover all injuries mentioned?". Medium priority - medicolegal if something was omitted. But since our focus is critical data, this is more of a nice-to-have completeness check. |

### Low Priority / Future Consideration

Proposals that would enhance the evaluation in edge cases or polish output, but have minimal patient safety or legal impact:

| Enhancement | Benchmark(s) | Rationale |
| --- | --- | --- |
| **Image/OCR Data** - If future integration of scene photos or driver license scans (for patient ID) occurs, ensure AI doesn't hallucinate or misread them. | _(Future)_ | Out of current scope. Low priority until such inputs exist. Would require new rubric. |
| **Spelling/Abbreviation Consistency** - Ensure certain key terms (drug names, units) are correctly spelled or standardized. | A-FMT2 (could extend)[\[235\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FMT2.yaml#L30-L38)[\[114\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FMT2.yaml#L40-L48) | Not explicitly scored aside from schema compliance (units). Not critical for meaning, more for professionalism. Low priority; could be QA manual check instead. |
| **Narrative vs Structured Alignment** - A holistic LLM check that the structured output and narrative don't contradict each other anywhere (beyond specific fields). | Possibly a global LLM check outside current rubrics. | This overlaps with A-EVD and A-NEG, and likely unnecessary if those do their jobs. Low priority as a separate item. Perhaps part of integration testing rather than per-case eval. |
| **Timeline Durations** - e.g. ensure total on-scene time or times between interventions aren't obviously implausible. | A-TMP4 idea (if define trends in time)[\[31\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP4.yaml#L9-L17) | Very complex and probably beyond needed scope. Low priority - likely not adding. If needed, could use simulation metadata to check if times are sequential. |
| **Patient Demographics** - If scenario provided age/sex and output got it wrong (rare, since that's usually given as structured input), flag it. | Could be A-FCT or Format check if we treat age as a field. | Low priority, as age/sex likely provided to AI correctly. If AI mis-states it, that's a hallucination (A-UNC1) or extraction fail if it misheard in narrative. So covered indirectly. |

## Threshold Review

We propose a few adjustments to passing thresholds for stricter adherence where clinically justified:

| Benchmark | Current Threshold | Recommended Threshold | Justification |
| --- | --- | --- | --- |
| **A-NEG (Rubric)** | 0.85 (rubric)[\[236\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L12-L20) / 0.90 (A-NEG1)[\[237\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-NEG1.yaml#L14-L22) | **0.90 (rubric)** / 0.90 (A-NEG1 unchanged) | Negation errors can invert meaning (e.g. documenting an allergy patient explicitly denied). Given high risk, require ~90% performance overall[\[1\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L2-L10)[\[3\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L16-L25). This means essentially no more than one minor negation slip in all cases. The sub-benchmarks already mostly at 0.85-0.90; raising rubric to 0.90 emphasizes importance[\[1\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-NEG.yaml#L2-L10). |
| **A-REF2 (Signature)** | 0.85[\[133\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF2.yaml#L14-L22) | **0.95** | A missing refusal signature or witness is a serious medicolegal gap, nearly as critical as missing risk explanation. Our rubric logic already would fail most such cases; setting 0.95 makes it explicit that if patient's refusal form info was stated it must appear. This aligns with 0032 requirement "signed refusal if possible"[\[132\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=%E2%80%A2%20Patient%20reminded%20they%20may,candidate%20for%20an%20alternative%20disposition). |
| **A-SFT4 (Reassessments)** | 0.90[\[78\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-SFT4.yaml#L14-L22) | **1.0** | With rubric A-SFT at MIN/1.0[\[80\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-SFT.yaml#L12-L19), any score <1.0 fails rubric anyway. For consistency and clarity, set A-SFT4 to 1.0 hard gate as well. Missing a required post-intervention reassessment (pain, BP, etc.) should be considered a full failure of that benchmark - these are critical checks after high-risk treatments. |
| **A-PRT1 (RSI)** | 0.90[\[88\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-PRT1.yaml#L13-L20) | 0.90 (no change) | Current threshold already high. We discussed possibly 1.0, but allowing one minor detail (e.g. missing one confirmation method out of two, while all else present) might be acceptable. Given weight 0.50, any significant omission fails rubric anyway. So keep 0.90. RSI is life-critical, but output might still be "Excellent" with 90% (e.g. all drugs, attempts, confirmation documented, just forgot to note "pre-oxygenation done"). That's okay. |
| **A-CMP (Rubric)** | 0.80[\[238\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/rubrics/A-CMP.yaml#L11-L19) | 0.85 | We recommend a slight bump overall for completeness. Important sections like transport and assessment should not be missing. Since many A-CMP sub-tests are binary (section present or not, etc.), an 0.80 threshold could potentially allow one section completely missing out of five and still pass (depending on weights). 0.85 ensures a bit more rigor - essentially no more than one minor section lapse. Not critical, but improves standard. |
| **A-BHV (Rubric)** | 0.90[\[209\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-BHV.yaml#L12-L19) | 0.90 (no change) | The rubric weighting already forces near perfection (especially with A-BHV1 as hard gate). We considered 0.95 to ensure capacity (BHV2) is captured if restraints were used, but since BHV1 is hard must and BHV2 at 0.90, rubric 0.90 is effectively strict. We will maintain 0.90, which demands both parts in most cases. |
| **A-UNC (Rubric)** | 0.95[\[224\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/rubrics/A-UNC.yaml#L12-L19) | 0.95 (no change) | This rubric essentially requires no hallucinations and flagging of all critical omissions. We debated 1.0 (zero misses allowed). Because weight favors hallucination (0.60) over omissions (0.40), an AI could theoretically miss flagging one item and still get ~96%. That's fine - e.g. if everything is perfect except it didn't mark one non-critical unknown, passing is okay. If it misses flagging any truly critical gap, that likely drops score below 0.95 anyway. So 0.95 is acceptable balance to avoid false fails on tiny issues. |

_Note:_ Benchmarks not listed above are recommended to remain at current thresholds, as they appear clinically appropriate based on our review. For instance, A-FCT1 at 0.90 (vitals)[\[239\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT1.yaml#L14-L22) is strict enough given minor rounding allowances, A-STR2 at 0.95 (stroke LKW/alert)[\[151\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR2.yaml#L14-L22) is right, etc. We focused on those where a change could notably impact safety/accuracy.

## Example Quality Assessment

Overall, the examples in benchmarks are realistic and clear. We identified a few cases where examples could be more representative of real EMS reports or cover edge scenarios:

| Benchmark | Issue with Current Example(s) | Current Example Text | Suggested Improved Example Text |
| --- | --- | --- | --- |
| **A-NEG3** (Implicit Negation) | Examples are good but all involve patient uncertainty. Could add one with _provider_ inference. | "_'lungs clear bilaterally' implies no respiratory distress, but output leaves respiratory fields blank._"[\[240\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-NEG3.yaml#L38-L46) (Already covers implicit). | **(Add)**: "_Narrative: 'No complaints other than mild cough.' Output incorrectly documents a host of negatives as present findings._" - Emphasize overgeneralizing beyond narrative. |
| **A-FCT4** (Impression Mismatch) | Current examples cover wrong impressions well. Could include a near-miss synonym to illustrate acceptable vs not. | "_ACCEPTABLE: 'heart attack' vs 'MI'_"[\[17\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-FCT4.yaml#L34-L42). | **(No change)** Actually examples are solid. Perhaps add: "_Ground truth: 'CVA', Output: 'seizure' - completely wrong impression._" to show a non-acceptable mismatch beyond synonyms. |
| **A-TMP1** (Event Order) | Could use an example with protocol nuance. Current example of RSI order is great[\[241\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP1.yaml#L39-L46). Maybe add one for an on-scene vs transport timing. | "_Output timeline shows transport departure before any documented vitals or exam despite detailed on-scene assessment in narrative._"[\[241\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TMP1.yaml#L39-L46) - this is already in example. | **(No change)**. Possibly: "_Narrative: 'Arrived hospital at 10:30 after 20 min scene time.' Output lists hospital arrival timestamp that precedes IV insertion and assessment times._" - to illustrate anachronism. This might be too detailed; skip if confusing. |
| **A-CMP1** (Missing Sections) | Current examples fine. Maybe include a conflation case. | "_Airport-transfer trace where Transfer info documented only in free text..._"[\[55\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP1.yaml#L38-L46) good. | **(Add)**: "_Narrative clearly describes a Response (crew, times) but output has no Response section (info jammed into Arrival)._ " - Shows section conflation as per inclusion[\[242\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/46a61cc0abaa75229d77b4360f1ebed301b0277e/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP1.yaml#L28-L36). |
| **A-CMP5** (DOA Fields) | Examples cover missing one of fields[\[243\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L37-L41). Possibly add scenario with base and standing order confusion. | "_Narrative: 'pronounced 06:31 by Dr. Chen' but output missing agency or method._"[\[243\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-CMP5.yaml#L37-L41). | **(No change)**. Maybe also: "_Narrative: Obvious death, no base contact per protocol, output fails to state 'per protocol/standing order' as method._" - subtle but important. |
| **A-REF1** (Risks) | Very thorough examples. Perhaps include capacity piece. | "_'Explained risks of refusing including death...' output says only 'Patient refused transport'._"[\[129\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF1.yaml#L43-L48). | **(Add)**: "_Narrative: 'Patient oriented x4, understands and still refuses.' Output omits any mention of decision capacity or risks discussed._" - highlighting both issues together. |
| **A-REF3** (Base Contact) | Good examples. Could add one partial: base noted but no physician name. | "_Narrative: 'Contacted base: Dr. Smith advised refusal acceptable' but output says only 'Patient refused.'_"[\[244\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-REF3.yaml#L40-L43) covers it. | **(No change)** - already clear. Perhaps explicitly mention "partial: output notes 'base contacted' but not name - still fail (0.80 partial per scale)". This is implicit. |
| **A-STR1** (Stroke Scale) | Examples solid. Possibly add multi-scale scenario. | "_'Multiple scales: CPSS positive, LAMS 4 - output only documented one.'_ "[\[149\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-STR1.yaml#L40-L44) covers it. | **(No change)**. Already covers if multiple scores given. |
| **A-TRM2** (Trauma Interventions) | Good examples for tourniquet and needle. Maybe include pelvic binder example or cric. | "_... output says only 'chest injury treated.'_"[\[168\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM2.yaml#L38-L43). | **(Add)**: "_Narrative: 'Pelvic binder applied for unstable pelvis' but output doesn't mention binder._" Also: "_'Performed needle decompression' but output omitted it'_ (already there)." These additions broaden examples to other interventions. |
| **A-TRM3** (Trauma Alert) | Example fine. Possibly clarify levels. | "\_'Called level 1 trauma to Memorial, trauma team notified' but output says only 'Transported to Memorial.'"[\[245\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-TRM3.yaml#L40-L43). | **(No change)**. This clearly shows the issue. Could add: "_Narrative: 'Trauma alert called' output not mention it._" which is essentially already there. |
| **A-OBS1** (APGAR) | Examples good (covers twin, APGAR, interventions). No glaring issues. | N/A (Examples cover APGAR omission, twin scenario, etc.)[\[109\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L40-L48). | **(No change)**. Possibly emphasize time: one example does mention "delivered at 14:32 must include time"[\[191\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS1.yaml#L40-L44) which is great. |
| **A-OBS2** (Pregnancy details) | Example covers missing G/P and twin, etc.[\[186\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS2.yaml#L40-L44). Could include postpartum hemorrhage scenario. | "\_'Twin pregnancy at 32 wks with bleeding' but output lacks gestational age and twin status.'"[\[185\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS2.yaml#L40-L43). | **(Add)**: "_Narrative: 'Placenta delivered, ~500 mL blood loss' but output doesn't mention placenta or EBL._" Actually, that exact text is in example[\[186\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-OBS2.yaml#L40-L44). It's fine. |
| **A-BHV1** (Restraints) | Good examples. Add one with both physical & chemical plus monitoring. | "_'Both types: Soft restraints applied, Versed 5mg given - both must be documented.'_"[\[208\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV1.yaml#L44-L48) covers it. Also mentions monitoring requirement. | **(No change)**. Already detailed. We just ensure narratives in tests reflect those elements so AI has opportunity to document them. |
| **A-BHV2** (Capacity) | Examples solid (5150 hold, incompetence)[\[202\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV2.yaml#L38-L42). Perhaps add scenario of patient refusing but clearly lacks capacity (implied consent). | "_'deemed incompetent... output lacks capacity assessment'_"[\[201\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-BHV2.yaml#L38-L41) is there. | **(No change)**. That captures it. If we wanted, we could add: "_Narrative: 'Patient is intoxicated, not oriented - treated under implied consent' but output doesn't explain lack capacity._" This is similar to what's given. |
| **A-UNC2** (Silent Omission) | Good examples. Perhaps clarify acceptable vs not with an example of correct "unknown" usage as mentioned. | Several fail examples e.g. refusal with blank risk[\[220\]](https://github.com/SimWerx/synthetic-data-epcr-narrative/blob/6a89478482d7598fd9cf3063f1aeb7daddc4e744/zy_experimental/soar-pydantic-eval/benchmarks/a-component/A-UNC2.yaml#L44-L49). No positive example. | **(Add)**: Not in YAML, but in documentation, illustrate a pass case: "_Narrative silent on pronouncement time; output: 'pronouncement_time: unknown' - this is correct handling._" This educates rather than changes evaluation. |

In summary, most examples are already well-chosen. The above suggestions either add additional scenarios or clarify acceptable documentation to guide users. Implementing these will further ensure the evaluation criteria are unambiguous and cover edge cases, without fundamentally altering the benchmarks.

## Summary Statistics

- **Benchmarks Reviewed**: 46 (a-component benchmarks).
- **Benchmarks with No Changes** (sound as-is): ~30. (Examples: Most **A-NEG**, **A-FMT**, **A-EVD1**, **A-PRT2**, **A-STR** benchmarks are solid.)
- **Minor Refinements Suggested** (threshold or example tweaks, clarity): ~10 benchmarks. (E.g. **A-NEG rubric** threshold, **A-REF2** threshold, example additions in **A-TRM2**, **A-BHV1** messaging about RASS.)
- **Significant Changes Needed**: 5 benchmarks (or groups) identified.
- Placeholder definitions: **A-TMP3**, **A-TMP4**, **A-CMP2-4**, **A-EVD3** (these count as one group of "to be defined" items).
- **A-FCT missing meds benchmark**.
- (The rest significant changes are adding new ones or merging into existing, as listed in backlog.)
- **New Benchmarks Proposed**: 2 explicitly (Medication Extraction A-FCT2, Evidence Contradiction A-EVD3) plus defining 3 placeholders (A-TMP3/4, A-CMP2/3/4 effectively) which were planned but not done. Also possibly a generalized Assessment completeness (if A-CMP4) but that's counted in placeholders.

In conclusion, the rubric and benchmark set is about 90% comprehensive for clinically relevant documentation fidelity. By implementing the above recommendations, especially the high-priority and critical items, we can achieve near-complete coverage of required EMS documentation elements and ensure Medic Copilot's outputs meet Denver's protocol standards and medicolegal expectations. The changes will tighten the evaluation where needed (negation, refusals, safety) and fill a few remaining gaps, resulting in a robust validation suite ready for production use.[\[140\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20Requirements%20for%20Refusal%20%E2%80%A2,authorizing%20refusal%20of%20care%20unless)[\[97\]](https://www.dmemsmd.org/sites/default/files/DMEMSMD%20Protocols%20July%202025%20FINAL%202025-07-14.pdf#:~:text=Documentation%20A,care%20to%20emergency%20department%20staff)