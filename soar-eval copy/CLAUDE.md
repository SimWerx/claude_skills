# CLAUDE.md â€” soar-pydantic-eval

For Claude Code: See `AGENTS.md` for project instructions.

## Quick Links

- **Agent instructions**: `AGENTS.md`
- **Active tasks**: `WORKING.md`
- **Rubric/benchmark concepts**: `docs/rubric-benchmark-overview.md`
- **LLM judge research**: `docs/lag-boolean-prompt-spec.md`
- **Rubric field specs**: `rubrics/FIELD_SPECS.md`
- **Benchmark field specs**: `benchmarks/FIELD_SPECS.md`
- **LLM prompt specs**: `evaluators/llm-judge/PROMPT_SPECS.md`
